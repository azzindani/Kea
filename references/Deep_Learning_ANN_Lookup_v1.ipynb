{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xNvr15NMI93"
      },
      "source": [
        "## Version 20240821"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzGjScgSt8W9"
      },
      "source": [
        "## 00 Importing Modules & Mounting Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbJ186eYbwSV"
      },
      "outputs": [],
      "source": [
        "!pip install ydata-profiling\n",
        "\n",
        "import pathlib\n",
        "import datetime\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import geopandas as gpd\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "import pickle\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import xgboost as xgb\n",
        "import tensorflow as tf\n",
        "import datetime as dt\n",
        "\n",
        "from scipy import stats as sm\n",
        "from IPython.display import Image\n",
        "from graphviz import Source\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report, mean_squared_error, r2_score, accuracy_score, average_precision_score, f1_score, precision_score\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder, OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from urllib.request import urlopen\n",
        "from io import BytesIO\n",
        "from zipfile import ZipFile\n",
        "from ydata_profiling import ProfileReport\n",
        "from tabulate import tabulate\n",
        "from tensorflow.keras import layers, losses, initializers, Model, regularizers, activations\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DKQdkJBZN7Oy"
      },
      "outputs": [],
      "source": [
        "'''from google.colab import drive\n",
        "drive.mount('/content/drive') #'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Tm7yrNoN8-P"
      },
      "outputs": [],
      "source": [
        "'''MAIN_PATH = str(pathlib.Path().resolve())\n",
        "WORK_PATH = MAIN_PATH + '/drive/MyDrive/Workspace'\n",
        "SOURCE_PATH = WORK_PATH + '/00_Data_Source'\n",
        "CACHE_PATH = WORK_PATH + '/00_Cache_Data' #'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PL56c4YuH6y"
      },
      "source": [
        "## 01 Choosing & Importing Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AES29-R3JUni"
      },
      "source": [
        "### 01.00 Importing Data from Zipfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OAO1VzbHJcuB"
      },
      "outputs": [],
      "source": [
        "filename = 'Diseases_And_Symptoms.zip' # replace this\n",
        "\n",
        "url = 'https://github.com/azzindani/00_Data_Source/raw/main/'+ filename\n",
        "http_response = urlopen(url)\n",
        "zipfile = ZipFile(BytesIO(http_response.read()))\n",
        "zipfile.extractall() #'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-hapLbZ9YU_h"
      },
      "outputs": [],
      "source": [
        "os.listdir()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j5BLnZR1Z_hQ"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(os.listdir()[1], encoding = 'ISO-8859-1')#, sep = ';')\n",
        "df.shape #'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqJI4S_NNrVf"
      },
      "source": [
        "### 01.01 Importing Main Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XKZeeC_yuomA"
      },
      "outputs": [],
      "source": [
        "'''filename = 'Uber_Fares.csv' # replace this\n",
        "\n",
        "url = 'https://github.com/azzindani/00_Data_Source/raw/main/'+ filename\n",
        "df = pd.read_csv(url, encoding = 'ISO-8859-1')#, sep = ';')\n",
        "df.shape #'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KbzzoKIj2iUB"
      },
      "outputs": [],
      "source": [
        "df.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "St-0d98v2Myk"
      },
      "outputs": [],
      "source": [
        "df.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-9KO3Mi2lKG"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tlSMRYlQuklR"
      },
      "outputs": [],
      "source": [
        "for column in df.columns:\n",
        "  if df[column].dtypes == 'object':\n",
        "    print(column)\n",
        "    print('-' * 100)\n",
        "    print(df[column].unique())\n",
        "    print('=' * 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijGWg9ve51iA"
      },
      "source": [
        "### 01.02 Importing Geo Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ci2aFwWG51Gn"
      },
      "outputs": [],
      "source": [
        "'''geo_path = 'https://raw.githubusercontent.com/PublicaMundi/MappingAPI/master/data/geojson/us-states.json' # replace this\n",
        "\n",
        "gdf = gpd.read_file(geo_path)\n",
        "gdf.head(2) #'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MAH6j1dF58sH"
      },
      "outputs": [],
      "source": [
        "'''gdf = gdf.rename(columns = {'name' : 'State'})\n",
        "gdf = gdf[['State', 'geometry']]\n",
        "gdf.head(2) #'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDb0JNRq5-kL"
      },
      "source": [
        "### 01.03 Importing Additional Data (for enrichment)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUoE7lZKuRXY"
      },
      "source": [
        "### 01.04 Dataframe Back Up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IE_4gRcluVme"
      },
      "outputs": [],
      "source": [
        "df_bu = df.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ofv3eTv72nkR"
      },
      "source": [
        "## 02 Data Structuring"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skphEhYa2sj-"
      },
      "source": [
        "### 02.01 Selecting & Dropping Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "romlgFiBrwL8"
      },
      "outputs": [],
      "source": [
        "column_list = [] # fill this\n",
        "\n",
        "df = df.drop(column_list, axis = 1)\n",
        "df.head(2) #'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kkSIuDI2zpY"
      },
      "source": [
        "### 02.02 Cleaning Text Object"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnGCmxzr22a6"
      },
      "source": [
        "#### 02.02.01 Convert Header to Proper Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pxibEhsD2xf-"
      },
      "outputs": [],
      "source": [
        "'''for x in df.columns:\n",
        "  y = x.title()\n",
        "  df = df.rename(columns = {x : y}) #'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8-W_5Pq25j4"
      },
      "source": [
        "#### 02.02.02 Strip Abnormal Spaces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IHBwRW6P27s0"
      },
      "outputs": [],
      "source": [
        "'''for x in df.columns:\n",
        "  if df[x].dtypes == 'object':\n",
        "    try:\n",
        "      df[x] = df[x].str.strip()\n",
        "    except:\n",
        "      pass #'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UdjluOC2_f6"
      },
      "source": [
        "#### 02.02.03 Convert Object Content to Proper Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PvP2ww0K3Bll"
      },
      "outputs": [],
      "source": [
        "'''for x in df.columns:\n",
        "  if df[x].dtypes == 'object':\n",
        "    for a in df[x].unique():\n",
        "      b = a.title()\n",
        "      df[x] = df[x].replace(a, b)\n",
        "  else:\n",
        "    pass #'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqhG5IiB3F-S"
      },
      "source": [
        "### 02.03 Coverting Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PE5qM6Dw3GkP"
      },
      "source": [
        "#### 02.03.01 Convert to date"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RUoX8lYp3IqU"
      },
      "outputs": [],
      "source": [
        "df.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kesMHW843OfM"
      },
      "outputs": [],
      "source": [
        "column_list = ['Activity Period Start Date'] # fill this\n",
        "\n",
        "for x in column_list:\n",
        "  try:\n",
        "    df[x] = pd.to_datetime(df[x])\n",
        "  except:\n",
        "    pass #'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vC8vfIaj3az_"
      },
      "source": [
        "#### 02.03.02 Convert to integer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ye7fsH6Wuv3g"
      },
      "outputs": [],
      "source": [
        "column_list = [] # fill this\n",
        "\n",
        "for x in column_list:\n",
        "  df[x] = df[x].astype('int') #'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNIzzPN43gCn"
      },
      "source": [
        "#### 02.03.03 Convert to Object (if necessary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "piio0k-LvUyv"
      },
      "outputs": [],
      "source": [
        "column_list = [] # fill this\n",
        "\n",
        "for x in column_list:\n",
        "  df[x] = df[x].astype('str') #'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yrd9pcfG3khR"
      },
      "source": [
        "#### 02.03.04 Replace 0 to Nan (if necessary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aBUvvU8k3mk-"
      },
      "outputs": [],
      "source": [
        "#df = df.replace(0, np.nan)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y14i2NUAn-Wb"
      },
      "source": [
        "#### 02.03.05 Filling 0 to Nan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eQfT9gTToGoz"
      },
      "outputs": [],
      "source": [
        "'''for column in df.columns:\n",
        "  if df[column].dtype == 'float64' or df[column].dtype == 'int64':\n",
        "    df[column] = df[column].fillna(0)\n",
        "    print(column)\n",
        "  else:\n",
        "    pass #'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrhWfBDaDkvl"
      },
      "source": [
        "#### 02.03.06 Dropping Nan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VcvD1FDqDliP"
      },
      "outputs": [],
      "source": [
        "#df = df.dropna()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZ5wzm6u3p8b"
      },
      "source": [
        "## 03 Data Cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAq3ZBRe3tuv"
      },
      "source": [
        "### 03.01 Replacing Variable Component"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_4di37C9vi0L"
      },
      "outputs": [],
      "source": [
        "'''value_dict = {} # fill this\n",
        "\n",
        "column_name = ''\n",
        "\n",
        "df[column_name] = df[column_name].replace(value_dict) #'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhN7QUOc3xcM"
      },
      "source": [
        "### 03.02 Add New Variable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o11m0VqGyHxJ"
      },
      "source": [
        "#### 03.02.01 Add by Math Calculation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lGpjGoVcxrkk"
      },
      "outputs": [],
      "source": [
        "'''new_var = '' # fill this\n",
        "obj_var1 = '' # fill this\n",
        "obj_var2 = '' # fill this\n",
        "\n",
        "df[new_var] = df[obj_var1] * df [obj_var2] #'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyvnQq22yRJW"
      },
      "source": [
        "#### 03.02.02 Add by Replacing \"Other\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_jw38_9QyQVC"
      },
      "outputs": [],
      "source": [
        "'''column_name = '' # fill this\n",
        "\n",
        "df[column_name].value_counts() #'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZJA4Fnfymrm"
      },
      "outputs": [],
      "source": [
        "'''value_thres = 1300\n",
        "\n",
        "replace_list = []\n",
        "\n",
        "df_dict = df[column_name].value_counts().to_dict()\n",
        "for i in df_dict:\n",
        "  if df_dict[i] < value_thres:\n",
        "    replace_list.append(i)\n",
        "\n",
        "replace_list #'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nkTtUFjLy1fZ"
      },
      "outputs": [],
      "source": [
        "'''df[column_name] = df[column_name].copy().replace(to_replace = replace_list, value = 'Other') #'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNL31wAI31lM"
      },
      "source": [
        "### 03.03 Inaccuracies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sRqdwAhJzAPj"
      },
      "outputs": [],
      "source": [
        "column_list = [] # fill this\n",
        "\n",
        "for x in column_list:\n",
        "  try:\n",
        "    df[x] = df[x].replace('0', np.nan)\n",
        "    df = df.dropna()\n",
        "  except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mn22d9xs4I6o"
      },
      "source": [
        "### 03.04 Handling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZB1pnlApyd8U"
      },
      "source": [
        "##### Data Distribution Check (Before)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "llH-hNJ2_sPy"
      },
      "outputs": [],
      "source": [
        "df.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "voNuk-oirOx2"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DeO-8jHm4F8b"
      },
      "outputs": [],
      "source": [
        "'''x = 'current_month_debit' # replace this\n",
        "y = 'current_month_balance' # replace this\n",
        "color = 'occupation' # replace this\n",
        "\n",
        "fig = px.histogram(\n",
        "  df,\n",
        "  x = x,\n",
        "  y = y,\n",
        "  color = color,\n",
        "  marginal = 'box',\n",
        "  hover_data = df.columns\n",
        ")\n",
        "\n",
        "fig.show() #'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OCvcFlfZM6jl"
      },
      "outputs": [],
      "source": [
        "'''x = 'current_month_debit' # replace this\n",
        "y = 'current_month_balance' # replace this\n",
        "color = 'occupation' # replace this\n",
        "\n",
        "fig = px.scatter(\n",
        "  df,\n",
        "  x = x,\n",
        "  y = y,\n",
        "  color = color,\n",
        "  marginal_x = 'histogram',\n",
        "  marginal_y = 'box',\n",
        "  hover_data = df.columns\n",
        ")\n",
        "\n",
        "fig.show() #'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tci2Qaok4Vt-"
      },
      "source": [
        "#### 03.04.01 Using IQR (Inter Quantile Range)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mt7FHMFz4YdV"
      },
      "outputs": [],
      "source": [
        "def iqr_thres(dataframe, column, th1 = 0.25, th3 = 0.75):\n",
        "  quartile1 = dataframe[column].quantile(th1)\n",
        "  quartile3 = dataframe[column].quantile(th3)\n",
        "  iqr = quartile3 - quartile1\n",
        "  upper_limit = quartile3 + 1.5 * iqr\n",
        "  lower_limit = quartile1 - 1.5 * iqr\n",
        "\n",
        "  return lower_limit, upper_limit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dRaHXuvQ4ZBb"
      },
      "outputs": [],
      "source": [
        "def check_outliers_iqr(dataframe, column):\n",
        "  lower_limit, upper_limit = iqr_thres(dataframe, column)\n",
        "  if dataframe[(dataframe[column] > upper_limit) | (dataframe[column] < lower_limit)].any(axis = None):\n",
        "    return True\n",
        "  else:\n",
        "    return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FRncku9Q4dLW"
      },
      "outputs": [],
      "source": [
        "def replace_iqr(dataframe, columns, th1 = 0.25, th3 = 0.75, replace = False):\n",
        "  data = []\n",
        "\n",
        "  for column in columns:\n",
        "    if dataframe[column].dtypes == 'int64' or dataframe[column].dtypes == 'float64':\n",
        "      if column != 'Outcome':\n",
        "        outliers_ = check_outliers_iqr(dataframe, column)\n",
        "        count = None\n",
        "        lower_limit, upper_limit = iqr_thres(dataframe, column, th1, th3)\n",
        "\n",
        "        if outliers_:\n",
        "          count = dataframe[(dataframe[column] > upper_limit) | (dataframe[column] < lower_limit)][column].count()\n",
        "          if replace:\n",
        "            if lower_limit < 0:\n",
        "              dataframe.loc[(dataframe[column] > upper_limit), column] = np.nan\n",
        "            else:\n",
        "              dataframe.loc[(dataframe[column] < lower_limit), column] = np.nan\n",
        "              dataframe.loc[(dataframe[column] > upper_limit), column] = np.nan\n",
        "        outliers_status = check_outliers_iqr(dataframe, column)\n",
        "        data.append([outliers_, outliers_status, count, column, lower_limit, upper_limit ])\n",
        "\n",
        "  table = tabulate(data, headers = ['Outliers (Previously)', 'Outliers', 'Count', 'Column', 'Lower Limit', 'Upper Limit'], tablefmt = 'rst', numalign = 'right')\n",
        "  print('Removing Outliers using IQR')\n",
        "  print(table)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GfPGmOvI4f89"
      },
      "outputs": [],
      "source": [
        "column_list = [] # fill this\n",
        "\n",
        "replace_iqr(\n",
        "  dataframe = df,\n",
        "  columns = column_list,\n",
        "  replace = True\n",
        ")\n",
        "df = df.dropna()#'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUeLtiYd4kMs"
      },
      "source": [
        "#### 03.04.02 Using Standard Deviation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gFPjk_Zb4j3m"
      },
      "outputs": [],
      "source": [
        "def std_thres(dataframe, column):\n",
        "  upper_limit = dataframe[column].mean() + 3 * dataframe[column].std()\n",
        "  lower_limit = dataframe[column].mean() - 3 * dataframe[column].std()\n",
        "\n",
        "  return lower_limit, upper_limit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rkImfexs4nbm"
      },
      "outputs": [],
      "source": [
        "def check_outliers_std(dataframe, column):\n",
        "  lower_limit, upper_limit = std_thres(dataframe, column)\n",
        "  if dataframe[(dataframe[column] > upper_limit) | (dataframe[column] < lower_limit)].any(axis = None):\n",
        "    return True\n",
        "  else:\n",
        "    return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gHycsqre4qX6"
      },
      "outputs": [],
      "source": [
        "def replace_std(dataframe, columns, replace = False):\n",
        "  data = []\n",
        "\n",
        "  for column in columns:\n",
        "    if dataframe[column].dtypes == 'int64' or dataframe[column].dtypes == 'float64':\n",
        "      if column != 'Outcome':\n",
        "        outliers_ = check_outliers_std(dataframe, column)\n",
        "        count = None\n",
        "        lower_limit, upper_limit = std_thres(dataframe, column)\n",
        "\n",
        "        if outliers_:\n",
        "          count = dataframe[(dataframe[column] > upper_limit) | (dataframe[column] < lower_limit)][column].count()\n",
        "          if replace:\n",
        "            if lower_limit < 0:\n",
        "              dataframe.loc[(dataframe[column] > upper_limit), column] = np.nan\n",
        "            else:\n",
        "              dataframe.loc[(dataframe[column] < lower_limit), column] = np.nan\n",
        "              dataframe.loc[(dataframe[column] > upper_limit), column] = np.nan\n",
        "        outliers_status = check_outliers_std(dataframe, column)\n",
        "        data.append([outliers_, outliers_status, count, column, lower_limit, upper_limit])\n",
        "\n",
        "  table = tabulate(data, headers = ['Outlier (Previously)', 'Outliers', 'Count', 'Column', 'Lower Limit', 'Upper Limit'], tablefmt = 'rst', numalign = 'right')\n",
        "  print('Removing Outliers using 3 Standard Deviation')\n",
        "  print(table)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D_pvh2IL4q2I"
      },
      "outputs": [],
      "source": [
        "column_list = [] # fill this\n",
        "\n",
        "replace_std(\n",
        "  dataframe = df,\n",
        "  columns = column_list,\n",
        "  replace = True\n",
        ")\n",
        "df = df.dropna()#'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEqxjPOT4vTP"
      },
      "source": [
        "### 03.05 Handling Missing / Zeros / Null\n",
        "##### Filling missing value (numerical only) is better using median than mean or mode"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVpvT5IV4zdY"
      },
      "source": [
        "#### 03.05.01 Detecting Zero Value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "is7a1I744wMK"
      },
      "outputs": [],
      "source": [
        "zero_columns = [] # fill this\n",
        "\n",
        "for x in df.columns:\n",
        "  if df[x].dtypes == 'int64' or df[x].dtypes == 'float64':\n",
        "    if (df[x] == 0).sum() != 0:\n",
        "      print(x, ':', str((df[x] == 0).sum()))\n",
        "      zero_columns.append(x)\n",
        "\n",
        "zero_columns #'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2yFMHRf43pd"
      },
      "source": [
        "#### 03.05.02 Detecting Nan / Non Available Value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PYM4yhj844Ix"
      },
      "outputs": [],
      "source": [
        "nan_columns = [] # fill this\n",
        "\n",
        "for x in df.columns:\n",
        "  if df[x].dtypes == 'object':\n",
        "    if (df[x] == np.nan).sum() or (df[x] == '-').sum() != 0:\n",
        "      print(x, ':', str((df[x] == np.nan).sum()))\n",
        "      nan_columns.append(x)\n",
        "\n",
        "nan_columns #'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w81kHjrH49xD"
      },
      "source": [
        "#### 03.05.03 Replacing Zero with Mean (for numerical value if median value == 0), if necessary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nLz--vIY5BzU"
      },
      "outputs": [],
      "source": [
        "'''column_list = [] # fill this\n",
        "\n",
        "df = df.replace(0, np.nan)\n",
        "\n",
        "for x in column_list:\n",
        "  df[x] = df[x].fillna(df[x].mean()) #'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBWAP-1J5Eyi"
      },
      "source": [
        "#### 03.05.04 Replacing Zero with Median (for numerical value if median value != 0), if necessary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oMvEl4xs5HWd"
      },
      "outputs": [],
      "source": [
        "'''column_list = [] # fill this\n",
        "\n",
        "df = df.replace(0, np.nan)\n",
        "\n",
        "for x in column_list:\n",
        "  df[x] = df[x].fillna(df[x].median()) #'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dog2-5ML5JQ6"
      },
      "source": [
        "#### 03.05.05 Replacing Zero with Mode (for categorical / object value), if necessary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dut4TUuq5NHK"
      },
      "outputs": [],
      "source": [
        "'''column_list = [] # fill this\n",
        "\n",
        "df = df.replace(0, np.nan)\n",
        "\n",
        "for x in column_list:\n",
        "  df[x] = df[x].fillna(df[x].mode()) #'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtFcqtOW5JNo"
      },
      "source": [
        "### 03.06 Handling Incomplete Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-9FaTrv5RlN"
      },
      "source": [
        "### 03.07 Handling Data Biases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8cfMYC15Uw3"
      },
      "source": [
        "### 03.08 Handling Duplicates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vSryzaSI5bNc"
      },
      "outputs": [],
      "source": [
        "#df = df.drop_duplicates()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sx0xbr3K5YLO"
      },
      "source": [
        "##### Data Distribution Check (After)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bA713Qoi5drf"
      },
      "outputs": [],
      "source": [
        "'''x = 'current_month_debit' # replace this\n",
        "y = 'current_month_balance' # replace this\n",
        "color = 'occupation' # replace this\n",
        "\n",
        "fig = px.histogram(\n",
        "  df,\n",
        "  x = x,\n",
        "  y = y,\n",
        "  color = color,\n",
        "  marginal = 'box',\n",
        "  hover_data = df.columns\n",
        ")\n",
        "\n",
        "fig.show() #'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RD2kIuYlgkRm"
      },
      "outputs": [],
      "source": [
        "'''x = 'current_month_debit' # replace this\n",
        "y = 'current_month_balance' # replace this\n",
        "color = 'occupation' # replace this\n",
        "\n",
        "fig = px.scatter(\n",
        "  df,\n",
        "  x = x,\n",
        "  y = y,\n",
        "  color = color,\n",
        "  marginal_x = 'histogram',\n",
        "  marginal_y = 'box',\n",
        "  hover_data = df.columns\n",
        ")\n",
        "\n",
        "fig.show() #'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1O3I_gU5p20"
      },
      "source": [
        "## 04 Enriching Data\n",
        "#### take other dataset, inside or outside from related dataset / business"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oiJULi5g1_a0"
      },
      "outputs": [],
      "source": [
        "'''location = 'Country' # replace this\n",
        "\n",
        "a = df[location].unique()\n",
        "b = gdf[location].unique()\n",
        "\n",
        "for i in a:\n",
        "  if i not in b:\n",
        "    print(i)\n",
        "\n",
        "print(50 * '=')\n",
        "\n",
        "for i in b:\n",
        "  if i not in a:\n",
        "    print(i) #'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7gZKqurz2DCs"
      },
      "outputs": [],
      "source": [
        "value_dict = {}\n",
        "\n",
        "try:\n",
        "  df[location] = df[location].replace(value_dict)\n",
        "except:\n",
        "  pass #'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9z-glw4U5r3Y"
      },
      "source": [
        "## 05 Data Validation\n",
        "#### Verifying consistency, quality, and security of data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXJgoIwCoisk"
      },
      "source": [
        "## 06 Exploration Data Analysis (Univariate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ICAXeqSDopgs"
      },
      "outputs": [],
      "source": [
        "'''data_profile = ProfileReport(\n",
        "  df,\n",
        "  correlations = {\n",
        "    'pearson' : {'calculate' : True},\n",
        "    'spearman' : {'calculate' : True},\n",
        "    'kendall' : {'calculate' : True},\n",
        "    'phi_k' : {'calculate' : True},\n",
        "    'cramers': {'calculate' : True},\n",
        "  },\n",
        ")\n",
        "\n",
        "data_profile #'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-cKf7u2fYR8"
      },
      "source": [
        "## 07 Select Variable X & Y | Splitting Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62vYCe3x4YmZ"
      },
      "source": [
        "#### 07.01 Data Balancing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zWLslMYI4lnm"
      },
      "outputs": [],
      "source": [
        "'''# Check Before Data Balancing\n",
        "y_var = 'HeartDisease'\n",
        "\n",
        "fig, ax = plt.subplots(figsize = (5, 5))\n",
        "sizes = [count for count in df[y_var].value_counts()]\n",
        "labels = list(df[y_var].value_counts().index)\n",
        "\n",
        "ax.pie(\n",
        "  x = sizes,\n",
        "  labels = labels,\n",
        "  autopct = '%1.1f%%',\n",
        ")\n",
        "plt.show() #'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nijbkHEP4svK"
      },
      "outputs": [],
      "source": [
        "'''n = 20000\n",
        "append_data = []\n",
        "\n",
        "for i in df[y_var].unique():\n",
        "  df_x = df[df[y_var] == i][:n]\n",
        "  append_data.append(df_x)\n",
        "\n",
        "append_df = pd.concat(append_data)\n",
        "append_df.shape #'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aE08oGEy4w8r"
      },
      "outputs": [],
      "source": [
        "'''# Check After Data Balancing\n",
        "\n",
        "fig, ax = plt.subplots(figsize = (5, 5))\n",
        "sizes = [count for count in append_df[y_var].value_counts()]\n",
        "labels = list(append_df[y_var].value_counts().index)\n",
        "\n",
        "ax.pie(\n",
        "  x = sizes,\n",
        "  labels = labels,\n",
        "  autopct = '%1.1f%%',\n",
        ")\n",
        "plt.show() #'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r0TzakFx4zOT"
      },
      "outputs": [],
      "source": [
        "#df = append_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvlFdORoEBsK"
      },
      "source": [
        "### 07.02 Label Encoding / One Hot Encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 07.02.01 First Method"
      ],
      "metadata": {
        "id": "tRp945chl4Kt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0xalcRFbECSh"
      },
      "outputs": [],
      "source": [
        "df.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_HpZe6myEEaa"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZ4RGCvmgmBe"
      },
      "outputs": [],
      "source": [
        "y_var = 'diseases'\n",
        "\n",
        "class_dict = {}\n",
        "count = 0\n",
        "for cat in df[y_var].unique():\n",
        "  class_dict[cat] = count\n",
        "  count = count + 1\n",
        "\n",
        "class_dict #'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O5nBbA4JxGPs"
      },
      "outputs": [],
      "source": [
        "rev_class_dict = {v: k for k, v in class_dict.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nV3EP91JjM7Z"
      },
      "outputs": [],
      "source": [
        "df[y_var] = df[y_var].replace(class_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 07.02.02 Second Method"
      ],
      "metadata": {
        "id": "IueFURQQmCAg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "columns = [] # fill selected columns\n",
        "\n",
        "for column in columns:\n",
        "  df[column] = df[column].astype('str')\n",
        "  print(df[column].unique())"
      ],
      "metadata": {
        "id": "k_rHkW7wmFN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoders = {}\n",
        "\n",
        "for column in columns:\n",
        "  le = LabelEncoder()\n",
        "  df[column] = le.fit_transform(df[column])\n",
        "  label_encoders[column] = le\n",
        "\n",
        "for column in columns:\n",
        "  labels = label_encoders[column].classes_\n",
        "  print(column)\n",
        "  print('-' * 50)\n",
        "  for i in range(len(labels)):\n",
        "    print(str(i), ':', labels[i])\n",
        "  print('=' * 50)"
      ],
      "metadata": {
        "id": "FmnAMegFmLac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_1vko8Gqthp"
      },
      "source": [
        "### 07.03 Define X & Y variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kooq8RzzhsA7"
      },
      "outputs": [],
      "source": [
        "df.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nEFQuk8tvpMK"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bePtz4z4rFd_"
      },
      "outputs": [],
      "source": [
        "#x_var = []\n",
        "x_var = df.columns[1:]\n",
        "y_var = 'diseases'\n",
        "\n",
        "x = df[x_var]\n",
        "y = df[y_var]\n",
        "\n",
        "x.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lKAu8eBPfNBn"
      },
      "outputs": [],
      "source": [
        "x = np.array(x)\n",
        "y = np.array(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_BVufTarKTH"
      },
      "source": [
        "### 07.04 Split Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "592JuZgZ9eHJ"
      },
      "outputs": [],
      "source": [
        "sc = StandardScaler()\n",
        "\n",
        "x_train, x_tosplit, y_train, y_tosplit = train_test_split(x, y, test_size = 0.3, random_state = 42)\n",
        "x_test, x_val, y_test, y_val = train_test_split(x_tosplit, y_tosplit, test_size = 0.4, random_state = 42)\n",
        "\n",
        "print('x_train shape :', x_train.shape)\n",
        "print('x_test shape :', x_test.shape)\n",
        "print('x_val shape :', x_val.shape)\n",
        "print('=' * 50)\n",
        "print('y_train shape :', y_train.shape)\n",
        "print('y_test shape :', y_test.shape)\n",
        "print('y_val shape :', y_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VzRcXNpKlq6B"
      },
      "outputs": [],
      "source": [
        "x_train = sc.fit_transform(x_train)\n",
        "x_test = sc.transform(x_test)\n",
        "x_val = sc.transform(x_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QF-yHydwWXZT"
      },
      "outputs": [],
      "source": [
        "y_classes = len(df[y_var].unique())\n",
        "y_classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fO0BqwOanfSs"
      },
      "source": [
        "## 08 Classification Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 08.01 Building Model"
      ],
      "metadata": {
        "id": "crVgPdlIkpYa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inp = layers.Input(shape = (x_train.shape[1],))\n",
        "\n",
        "x = layers.Embedding(input_dim = 1024, output_dim = 64)(inp)\n",
        "x = layers.Conv1D(128, 5, activation = 'relu')(x)\n",
        "#x = layers.Dense(units = 1024, activation = 'relu')(x)\n",
        "#x = residual_block(x, 1024)\n",
        "#x = layers.Bidirectional(layers.LSTM(64,  return_sequences = True))(x)\n",
        "#x = layers.Bidirectional(layers.LSTM(32))(x)\n",
        "x = layers.Flatten()(x)\n",
        "#x = layers.Dense(units = 1024, activation = 'relu')(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Activation('relu')(x)\n",
        "#x = layers.Dropout(0.05)(x)\n",
        "x = layers.Dense(units = y_classes, activation = 'softmax', name = 'fc' + str(10))(x)"
      ],
      "metadata": {
        "id": "POde7AWK39Jf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def residual_block(inputs, units):\n",
        "  x = layers.Dense(units)(inputs)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.Activation('relu')(x)\n",
        "  x = layers.Add()([inputs, x])\n",
        "  x = layers.Activation('relu')(x)\n",
        "  return x"
      ],
      "metadata": {
        "id": "l_rX2yVBd_A1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def inception_block(inputs, filters):\n",
        "    conv1 = layers.Conv1D(filters, kernel_size = 1, padding = 'same', activation = 'relu')(inputs)\n",
        "    conv2 = layers.Conv1D(filters, kernel_size = 3, padding = 'same', activation = 'relu')(inputs)\n",
        "    conv3 = layers.Conv1D(filters, kernel_size = 5, padding = 'same', activation = 'relu')(inputs)\n",
        "    pool = layers.MaxPooling1D(pool_size = 3, strides = 1, padding = 'same')(inputs)\n",
        "    pool = layers.Conv1D(filters, kernel_size = 1, padding = 'same', activation = 'relu')(pool)\n",
        "    x = layers.concatenate([conv1, conv2, conv3, pool], axis = -1)\n",
        "    return x"
      ],
      "metadata": {
        "id": "sEh9DExkZm2F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp = layers.Input(shape = (x_train.shape[1],))\n",
        "\n",
        "x = layers.Reshape((x_train.shape[1], 1))(inp)\n",
        "#x = inception_block(x, 16)\n",
        "x = inception_block(x, 32)\n",
        "#x = inception_block(x, 64)\n",
        "#x = inception_block(x, 128)\n",
        "#x = inception_block(x, 64)\n",
        "#x = inception_block(x, 32)\n",
        "#x = inception_block(x, 16)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(units = 1024, activation = 'relu')(x)\n",
        "x = layers.Dense(units = y_classes, activation = 'softmax', name = 'fc' + str(10))(x) #'''"
      ],
      "metadata": {
        "id": "eIS5pjzcZnQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VUJ9HzoyWA39"
      },
      "outputs": [],
      "source": [
        "inp = layers.Input(shape = (x_train.shape[1],))\n",
        "\n",
        "x = layers.Dense(units = 1024, activation = 'relu')(inp)\n",
        "\n",
        "x = residual_block(x, 1024)\n",
        "\n",
        "x = layers.Dense(units = 1024, activation = 'relu')(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Activation('relu')(x)\n",
        "\n",
        "x = layers.Dense(units = y_classes, activation = 'softmax', name = 'fc' + str(10))(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kkynE7RTWbCr"
      },
      "outputs": [],
      "source": [
        "model = Model(inputs = inp, outputs = x, name = 'Model_X')\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "  optimizer = 'adam',\n",
        "  loss = losses.sparse_categorical_crossentropy,\n",
        "  metrics = ['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "t-Y07pYPk1Td"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2KP00epRhZ_"
      },
      "source": [
        "### 08.02 Set Up Threshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iiubjBS-WUZJ"
      },
      "outputs": [],
      "source": [
        "class MyThresholdCallback(tf.keras.callbacks.Callback):\n",
        "  def __init__(self, threshold):\n",
        "    super(MyThresholdCallback, self).__init__()\n",
        "    self.threshold = threshold\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    val_acc = logs['val_accuracy']\n",
        "    acc = logs['accuracy']\n",
        "    if val_acc >= self.threshold and acc >= self.threshold:\n",
        "        self.model.stop_training = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GXIbG4nPWkBs"
      },
      "outputs": [],
      "source": [
        "es_callback = MyThresholdCallback(threshold = 0.98)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7MEhGSLRkVS"
      },
      "source": [
        "### 08.03 Model Training (Data Validation Included)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yP7u1I60Wnl8"
      },
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "  x_train,\n",
        "  y_train,\n",
        "  batch_size = 512,\n",
        "  epochs = 5,\n",
        "  validation_data = (x_val, y_val),\n",
        "  callbacks = es_callback\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uYo9sE3GQJj4"
      },
      "outputs": [],
      "source": [
        "val_loss = history.history['val_loss']\n",
        "loss = history.history['loss']\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "epochs = range(1, len(acc)+1, 1)\n",
        "\n",
        "plt.plot(epochs, acc, 'r--', label = 'Training Accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label = 'Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.ylabel('acc')\n",
        "plt.xlabel('epochs')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'r--', label = 'Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label = 'Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epochs')\n",
        "plt.legend()\n",
        "plt.figure()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umushGQ2Rn1L"
      },
      "source": [
        "### 08.04 Model Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LM1w364loAAF"
      },
      "outputs": [],
      "source": [
        "model.evaluate(x_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IW7dW2frRw3s"
      },
      "source": [
        "### 08.05 Checking The Result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jugLV-bRQcPV"
      },
      "source": [
        "#### 08.05.01 Classification Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GY7D_PfAo8Cw"
      },
      "outputs": [],
      "source": [
        "y_predicted = np.argmax(model.predict(x_test), axis = -1)\n",
        "cr = classification_report(y_test, y_predicted)\n",
        "\n",
        "print('Classification Report\\n', cr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOplNXD4QgVu"
      },
      "source": [
        "#### 08.05.02 Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HVTbSfzbPB-o"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(y_test, y_predicted)\n",
        "cm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NAlJTLkHpJ3w"
      },
      "outputs": [],
      "source": [
        "'''print('Confusion Matrix')\n",
        "plt.figure(figsize = (5, 3))\n",
        "sns.heatmap(cm, annot = True, fmt = 'd')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show() #'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6DVs6QJQjDh"
      },
      "source": [
        "#### 08.05.03 Prediction Table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9T1wQJGMQmbU"
      },
      "outputs": [],
      "source": [
        "test_label = []\n",
        "predict_label = []\n",
        "label_name =  []\n",
        "predict_name = []\n",
        "prediction_score = []\n",
        "\n",
        "for i in range(0, 100): #x_test.shape[0]):\n",
        "  test_label.append(y_test[i])\n",
        "  t_label = rev_class_dict[y_test[i]]\n",
        "  label_name.append(t_label)\n",
        "\n",
        "  img = x_test[i]\n",
        "  img = tf.expand_dims(img, axis = 0)\n",
        "  prediction = model.predict(img)\n",
        "  dense = prediction.reshape(-1).tolist()\n",
        "  score = max(dense)\n",
        "  index = dense.index(score)\n",
        "  predict_label.append(index)\n",
        "\n",
        "  p_label = rev_class_dict[index]\n",
        "  predict_name.append(p_label)\n",
        "\n",
        "  prediction_score.append(score)\n",
        "\n",
        "prediction_result = pd.DataFrame({\n",
        "  'label_num' : test_label,\n",
        "  'label_name' : label_name,\n",
        "  'predict_num' : predict_label,\n",
        "  'predict_name' : predict_name,\n",
        "  'predict_score' : prediction_score,\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lYiMI32KQrvm"
      },
      "outputs": [],
      "source": [
        "prediction_result['pred_check'] = prediction_result['label_num'] == prediction_result['predict_num']\n",
        "prediction_result.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEoDDDQVRBv7"
      },
      "source": [
        "#### 08.05.04.F1 Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QxyacRebRE1b"
      },
      "outputs": [],
      "source": [
        "labels = df[y_var].tolist()\n",
        "\n",
        "f1_scores = f1_score(prediction_result['label_name'], prediction_result['predict_name'], average = None, labels = labels)\n",
        "f1_dict = {label : score for label, score in zip(labels, f1_scores)}\n",
        "\n",
        "f1_df = pd.DataFrame(list(f1_dict.items()), columns = ['class', 'f1_score'])\n",
        "f1_df = f1_df.sort_values(by = 'f1_score', ascending = False).reset_index(drop = True)\n",
        "f1_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DfoWGHukRFiU"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (15, 20), dpi = 100)\n",
        "sns.barplot(x = f1_df['f1_score'], y = f1_df['class'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhfUMEZzRIH_"
      },
      "source": [
        "#### 08.05.05 False Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EBdmO_VwRK1Y"
      },
      "outputs": [],
      "source": [
        "false_pred = prediction_result[prediction_result['pred_check'] == False].sort_values('predict_score', ascending = False)\n",
        "false_pred.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "false = round(false_pred.shape[0] / x_test.shape[0] * 100, 2)\n",
        "print('Amount of False Prediction :', false, '%')"
      ],
      "metadata": {
        "id": "Ld_e8iUTZ6SV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 09 Regression Model"
      ],
      "metadata": {
        "id": "-F5c1WD4qypx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 09.01 Building Model"
      ],
      "metadata": {
        "id": "2uPYTSmdq54f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inp = layers.Input(shape = (x_train.shape[1],))\n",
        "\n",
        "x = layers.Dense(units = 128, kernel_initializer = 'normal', activation = 'relu')(inp)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Activation('relu')(x)\n",
        "\n",
        "x = layers.Dense(units = 256, kernel_initializer = 'normal', activation = 'relu')(inp)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Activation('relu')(x)\n",
        "\n",
        "x = layers.Dense(units = 512, kernel_initializer = 'normal', activation = 'relu')(inp)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Activation('relu')(x)\n",
        "\n",
        "x = layers.Dense(units = 1024, kernel_initializer = 'normal', activation = 'relu')(inp)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Activation('relu')(x)\n",
        "\n",
        "x = layers.Dense(units = 512, kernel_initializer = 'normal', activation = 'relu')(inp)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Activation('relu')(x)\n",
        "\n",
        "x = layers.Dense(units = 1, kernel_initializer = 'normal', activation = 'linear')(x)"
      ],
      "metadata": {
        "id": "N4OsVPd6sdIQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(inputs = inp, outputs = x, name = 'Model_X')\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "Naf5P_Y-sejo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "error = 'mse'\n",
        "#error = 'mean_absolute_error'\n",
        "error_val = 'val_' + error\n",
        "\n",
        "model.compile(\n",
        "  optimizer = 'adam',\n",
        "  loss = error,\n",
        "  metrics = [error]\n",
        ")"
      ],
      "metadata": {
        "id": "Tu9fKGWOsgYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 09.02 Set Up Threshold"
      ],
      "metadata": {
        "id": "wyyD67u_q833"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyThresholdCallback(tf.keras.callbacks.Callback):\n",
        "  def __init__(self, threshold):\n",
        "    super(MyThresholdCallback, self).__init__()\n",
        "    self.threshold = threshold\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    val_acc = logs['val_mean_absolute_error']\n",
        "    acc = logs['mean_absolute_error']\n",
        "    if val_acc <= self.threshold and acc <= self.threshold:\n",
        "        self.model.stop_training = True"
      ],
      "metadata": {
        "id": "vB6sMhsPsj_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "es_callback = MyThresholdCallback(threshold = 2500)"
      ],
      "metadata": {
        "id": "dVt9t0XZslzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 09.03 Model Training (Data Validation Included)"
      ],
      "metadata": {
        "id": "MTjac9-srA8a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "  x_train,\n",
        "  y_train,\n",
        "  batch_size = 512,\n",
        "  epochs = 5,\n",
        "  validation_data = (x_val, y_val),\n",
        "  callbacks = es_callback\n",
        ")"
      ],
      "metadata": {
        "id": "7eSVTjFFs947"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_loss = history.history['val_loss']\n",
        "loss = history.history['loss']\n",
        "acc = history.history[error]\n",
        "val_acc = history.history[error_val]\n",
        "\n",
        "epochs = range(1, len(acc)+1, 1)\n",
        "\n",
        "plt.plot(epochs, acc, 'r--', label = 'Training Error')\n",
        "plt.plot(epochs, val_acc, 'b', label = 'Validation Error')\n",
        "plt.title('Training and Validation Error')\n",
        "plt.ylabel(error)\n",
        "plt.xlabel('epochs')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'r--', label = 'Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label = 'Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epochs')\n",
        "plt.legend()\n",
        "plt.figure()"
      ],
      "metadata": {
        "id": "ekp05yebtCiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 09.04 Model Testing"
      ],
      "metadata": {
        "id": "YpqL5HWtrOgX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "id": "Vi_IVPN2tEmp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 09.05 Checking The Result\n",
        "#### Prediction Table"
      ],
      "metadata": {
        "id": "WcLAS4omrP3n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_predicted = model.predict(x_test)"
      ],
      "metadata": {
        "id": "Jg1B3fENtOBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "true_y = []\n",
        "predicted_y = []\n",
        "errors = []\n",
        "\n",
        "for i in range(0, 100): #x_test.shape[0]):\n",
        "  true_y.append(y_test[i])\n",
        "  predicted_y.append(y_predicted[i][0])\n",
        "  rmse = np.sqrt(np.mean((y_test[i] - y_predicted[i][0]) ** 2))\n",
        "  errors.append(rmse)\n",
        "\n",
        "prediction_result = pd.DataFrame({\n",
        "  'true_y' : true_y,\n",
        "  'predicted_y' : predicted_y,\n",
        "  error : errors,\n",
        "})\n",
        "\n",
        "prediction_result = prediction_result.sort_values(by = error, ascending = True).reset_index(drop = True)\n",
        "display(prediction_result.head())\n",
        "display(prediction_result.tail())"
      ],
      "metadata": {
        "id": "tfsguSha1puG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10 Saving Trained Model"
      ],
      "metadata": {
        "id": "lcooS9r4qreY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''filename = str(dt.datetime.today().strftime('%Y%m%d_%H%M'))\n",
        "save_dir = '/content/' + filename\n",
        "\n",
        "model_json = model.to_json()\n",
        "with open (save_dir + '.json', 'w') as json_file:\n",
        "  json_file.write('/content/' + model_json)\n",
        "\n",
        "model.save(save_dir + '.h5') #'''"
      ],
      "metadata": {
        "id": "9wymsgwpqxOo"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}