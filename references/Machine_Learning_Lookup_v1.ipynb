{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xNvr15NMI93"
      },
      "source": [
        "## Version 20240815"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzGjScgSt8W9"
      },
      "source": [
        "## 00 Importing Modules & Mounting Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbJ186eYbwSV"
      },
      "outputs": [],
      "source": [
        "!pip install ydata-profiling\n",
        "\n",
        "import pathlib\n",
        "import datetime\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import geopandas as gpd\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "import pickle\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import xgboost as xgb\n",
        "\n",
        "from scipy import stats as sm\n",
        "from IPython.display import Image\n",
        "from graphviz import Source\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report, mean_squared_error, r2_score, accuracy_score, average_precision_score, f1_score, precision_score\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder, OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from urllib.request import urlopen\n",
        "from io import BytesIO\n",
        "from zipfile import ZipFile\n",
        "from ydata_profiling import ProfileReport\n",
        "from tabulate import tabulate\n",
        "from time import sleep\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DKQdkJBZN7Oy"
      },
      "outputs": [],
      "source": [
        "'''from google.colab import drive\n",
        "drive.mount('/content/drive') #'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Tm7yrNoN8-P"
      },
      "outputs": [],
      "source": [
        "'''MAIN_PATH = str(pathlib.Path().resolve())\n",
        "WORK_PATH = MAIN_PATH + '/drive/MyDrive/Workspace'\n",
        "SOURCE_PATH = WORK_PATH + '/00_Data_Source'\n",
        "CACHE_PATH = WORK_PATH + '/00_Cache_Data' #'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PL56c4YuH6y"
      },
      "source": [
        "## 01 Choosing & Importing Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AES29-R3JUni"
      },
      "source": [
        "### 01.00 Importing Data from Zipfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OAO1VzbHJcuB"
      },
      "outputs": [],
      "source": [
        "'''filename = 'Diseases_And_Symptoms.zip' # replace this\n",
        "\n",
        "url = 'https://github.com/azzindani/00_Data_Source/raw/main/'+ filename\n",
        "http_response = urlopen(url)\n",
        "zipfile = ZipFile(BytesIO(http_response.read()))\n",
        "zipfile.extractall() #'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-hapLbZ9YU_h"
      },
      "outputs": [],
      "source": [
        "os.listdir()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j5BLnZR1Z_hQ"
      },
      "outputs": [],
      "source": [
        "'''df = pd.read_csv(os.listdir()[1], encoding = 'ISO-8859-1')#, sep = ';')\n",
        "df.shape #'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqJI4S_NNrVf"
      },
      "source": [
        "### 01.01 Importing Main Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XKZeeC_yuomA"
      },
      "outputs": [],
      "source": [
        "filename = 'Bank_Customer_Churn.csv' # replace this\n",
        "\n",
        "url = 'https://github.com/azzindani/00_Data_Source/raw/main/'+ filename\n",
        "df = pd.read_csv(url, encoding = 'ISO-8859-1')#, sep = ';')\n",
        "df.shape #'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KbzzoKIj2iUB"
      },
      "outputs": [],
      "source": [
        "df.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "St-0d98v2Myk"
      },
      "outputs": [],
      "source": [
        "df.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-9KO3Mi2lKG"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tlSMRYlQuklR"
      },
      "outputs": [],
      "source": [
        "for column in df.columns:\n",
        "  if df[column].dtypes == 'object':\n",
        "    print(column)\n",
        "    print('-' * 100)\n",
        "    print(df[column].unique())\n",
        "    print('=' * 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijGWg9ve51iA"
      },
      "source": [
        "### 01.02 Importing Geo Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ci2aFwWG51Gn"
      },
      "outputs": [],
      "source": [
        "'''geo_path = 'https://raw.githubusercontent.com/PublicaMundi/MappingAPI/master/data/geojson/us-states.json' # replace this\n",
        "\n",
        "gdf = gpd.read_file(geo_path)\n",
        "gdf.head(2) #'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MAH6j1dF58sH"
      },
      "outputs": [],
      "source": [
        "'''gdf = gdf.rename(columns = {'name' : 'State'})\n",
        "gdf = gdf[['State', 'geometry']]\n",
        "gdf.head(2) #'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDb0JNRq5-kL"
      },
      "source": [
        "### 01.03 Importing Additional Data (for enrichment)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUoE7lZKuRXY"
      },
      "source": [
        "### 01.04 Dataframe Back Up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IE_4gRcluVme"
      },
      "outputs": [],
      "source": [
        "df_bu = df.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ofv3eTv72nkR"
      },
      "source": [
        "## 02 Data Structuring"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skphEhYa2sj-"
      },
      "source": [
        "### 02.01 Selecting & Dropping Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "romlgFiBrwL8"
      },
      "outputs": [],
      "source": [
        "column_list = [] # fill this\n",
        "\n",
        "df = df.drop(column_list, axis = 1)\n",
        "df.head(2) #'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kkSIuDI2zpY"
      },
      "source": [
        "### 02.02 Cleaning Text Object"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnGCmxzr22a6"
      },
      "source": [
        "#### 02.02.01 Convert Header to Proper Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pxibEhsD2xf-"
      },
      "outputs": [],
      "source": [
        "'''for x in df.columns:\n",
        "  y = x.title()\n",
        "  df = df.rename(columns = {x : y}) #'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8-W_5Pq25j4"
      },
      "source": [
        "#### 02.02.02 Strip Abnormal Spaces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IHBwRW6P27s0"
      },
      "outputs": [],
      "source": [
        "'''for x in df.columns:\n",
        "  if df[x].dtypes == 'object':\n",
        "    try:\n",
        "      df[x] = df[x].str.strip()\n",
        "    except:\n",
        "      pass #'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UdjluOC2_f6"
      },
      "source": [
        "#### 02.02.03 Convert Object Content to Proper Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PvP2ww0K3Bll"
      },
      "outputs": [],
      "source": [
        "'''for x in df.columns:\n",
        "  if df[x].dtypes == 'object':\n",
        "    for a in df[x].unique():\n",
        "      b = a.title()\n",
        "      df[x] = df[x].replace(a, b)\n",
        "  else:\n",
        "    pass #'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqhG5IiB3F-S"
      },
      "source": [
        "### 02.03 Coverting Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PE5qM6Dw3GkP"
      },
      "source": [
        "#### 02.03.01 Convert to date"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RUoX8lYp3IqU"
      },
      "outputs": [],
      "source": [
        "df.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kesMHW843OfM"
      },
      "outputs": [],
      "source": [
        "column_list = ['Activity Period Start Date'] # fill this\n",
        "\n",
        "for x in column_list:\n",
        "  try:\n",
        "    df[x] = pd.to_datetime(df[x])\n",
        "  except:\n",
        "    pass #'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vC8vfIaj3az_"
      },
      "source": [
        "#### 02.03.02 Convert to integer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ye7fsH6Wuv3g"
      },
      "outputs": [],
      "source": [
        "column_list = [] # fill this\n",
        "\n",
        "for x in column_list:\n",
        "  df[x] = df[x].astype('int') #'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNIzzPN43gCn"
      },
      "source": [
        "#### 02.03.03 Convert to Object (if necessary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "piio0k-LvUyv"
      },
      "outputs": [],
      "source": [
        "column_list = [] # fill this\n",
        "\n",
        "for x in column_list:\n",
        "  df[x] = df[x].astype('str') #'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yrd9pcfG3khR"
      },
      "source": [
        "#### 02.03.04 Replace 0 to Nan (if necessary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aBUvvU8k3mk-"
      },
      "outputs": [],
      "source": [
        "#df = df.replace(0, np.nan)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y14i2NUAn-Wb"
      },
      "source": [
        "#### 02.03.05 Filling 0 to Nan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eQfT9gTToGoz"
      },
      "outputs": [],
      "source": [
        "'''for column in df.columns:\n",
        "  if df[column].dtype == 'float64' or df[column].dtype == 'int64':\n",
        "    df[column] = df[column].fillna(0)\n",
        "    print(column)\n",
        "  else:\n",
        "    pass #'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrhWfBDaDkvl"
      },
      "source": [
        "#### 02.03.06 Dropping Nan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VcvD1FDqDliP"
      },
      "outputs": [],
      "source": [
        "#df = df.dropna()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZ5wzm6u3p8b"
      },
      "source": [
        "## 03 Data Cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAq3ZBRe3tuv"
      },
      "source": [
        "### 03.01 Replacing Variable Component"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_4di37C9vi0L"
      },
      "outputs": [],
      "source": [
        "'''value_dict = {} # fill this\n",
        "\n",
        "column_name = ''\n",
        "\n",
        "df[column_name] = df[column_name].replace(value_dict) #'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhN7QUOc3xcM"
      },
      "source": [
        "### 03.02 Add New Variable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o11m0VqGyHxJ"
      },
      "source": [
        "#### 03.02.01 Add by Math Calculation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lGpjGoVcxrkk"
      },
      "outputs": [],
      "source": [
        "'''new_var = '' # fill this\n",
        "obj_var1 = '' # fill this\n",
        "obj_var2 = '' # fill this\n",
        "\n",
        "df[new_var] = df[obj_var1] * df [obj_var2] #'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyvnQq22yRJW"
      },
      "source": [
        "#### 03.02.02 Add by Replacing \"Other\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_jw38_9QyQVC"
      },
      "outputs": [],
      "source": [
        "'''column_name = '' # fill this\n",
        "\n",
        "df[column_name].value_counts() #'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZJA4Fnfymrm"
      },
      "outputs": [],
      "source": [
        "'''value_thres = 1300\n",
        "\n",
        "replace_list = []\n",
        "\n",
        "df_dict = df[column_name].value_counts().to_dict()\n",
        "for i in df_dict:\n",
        "  if df_dict[i] < value_thres:\n",
        "    replace_list.append(i)\n",
        "\n",
        "replace_list #'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nkTtUFjLy1fZ"
      },
      "outputs": [],
      "source": [
        "'''df[column_name] = df[column_name].copy().replace(to_replace = replace_list, value = 'Other') #'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNL31wAI31lM"
      },
      "source": [
        "### 03.03 Inaccuracies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sRqdwAhJzAPj"
      },
      "outputs": [],
      "source": [
        "column_list = [] # fill this\n",
        "\n",
        "for x in column_list:\n",
        "  try:\n",
        "    df[x] = df[x].replace('0', np.nan)\n",
        "    df = df.dropna()\n",
        "  except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mn22d9xs4I6o"
      },
      "source": [
        "### 03.04 Handling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZB1pnlApyd8U"
      },
      "source": [
        "##### Data Distribution Check (Before)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "llH-hNJ2_sPy"
      },
      "outputs": [],
      "source": [
        "df.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "voNuk-oirOx2"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DeO-8jHm4F8b"
      },
      "outputs": [],
      "source": [
        "'''x = 'current_month_debit' # replace this\n",
        "y = 'current_month_balance' # replace this\n",
        "color = 'occupation' # replace this\n",
        "\n",
        "fig = px.histogram(\n",
        "  df,\n",
        "  x = x,\n",
        "  y = y,\n",
        "  color = color,\n",
        "  marginal = 'box',\n",
        "  hover_data = df.columns\n",
        ")\n",
        "\n",
        "fig.show() #'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OCvcFlfZM6jl"
      },
      "outputs": [],
      "source": [
        "'''x = 'current_month_debit' # replace this\n",
        "y = 'current_month_balance' # replace this\n",
        "color = 'occupation' # replace this\n",
        "\n",
        "fig = px.scatter(\n",
        "  df,\n",
        "  x = x,\n",
        "  y = y,\n",
        "  color = color,\n",
        "  marginal_x = 'histogram',\n",
        "  marginal_y = 'box',\n",
        "  hover_data = df.columns\n",
        ")\n",
        "\n",
        "fig.show() #'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tci2Qaok4Vt-"
      },
      "source": [
        "#### 03.04.01 Using IQR (Inter Quantile Range)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mt7FHMFz4YdV"
      },
      "outputs": [],
      "source": [
        "def iqr_thres(dataframe, column, th1 = 0.25, th3 = 0.75):\n",
        "  quartile1 = dataframe[column].quantile(th1)\n",
        "  quartile3 = dataframe[column].quantile(th3)\n",
        "  iqr = quartile3 - quartile1\n",
        "  upper_limit = quartile3 + 1.5 * iqr\n",
        "  lower_limit = quartile1 - 1.5 * iqr\n",
        "\n",
        "  return lower_limit, upper_limit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dRaHXuvQ4ZBb"
      },
      "outputs": [],
      "source": [
        "def check_outliers_iqr(dataframe, column):\n",
        "  lower_limit, upper_limit = iqr_thres(dataframe, column)\n",
        "  if dataframe[(dataframe[column] > upper_limit) | (dataframe[column] < lower_limit)].any(axis = None):\n",
        "    return True\n",
        "  else:\n",
        "    return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FRncku9Q4dLW"
      },
      "outputs": [],
      "source": [
        "def replace_iqr(dataframe, columns, th1 = 0.25, th3 = 0.75, replace = False):\n",
        "  data = []\n",
        "\n",
        "  for column in columns:\n",
        "    if dataframe[column].dtypes == 'int64' or dataframe[column].dtypes == 'float64':\n",
        "      if column != 'Outcome':\n",
        "        outliers_ = check_outliers_iqr(dataframe, column)\n",
        "        count = None\n",
        "        lower_limit, upper_limit = iqr_thres(dataframe, column, th1, th3)\n",
        "\n",
        "        if outliers_:\n",
        "          count = dataframe[(dataframe[column] > upper_limit) | (dataframe[column] < lower_limit)][column].count()\n",
        "          if replace:\n",
        "            if lower_limit < 0:\n",
        "              dataframe.loc[(dataframe[column] > upper_limit), column] = np.nan\n",
        "            else:\n",
        "              dataframe.loc[(dataframe[column] < lower_limit), column] = np.nan\n",
        "              dataframe.loc[(dataframe[column] > upper_limit), column] = np.nan\n",
        "        outliers_status = check_outliers_iqr(dataframe, column)\n",
        "        data.append([outliers_, outliers_status, count, column, lower_limit, upper_limit ])\n",
        "\n",
        "  table = tabulate(data, headers = ['Outliers (Previously)', 'Outliers', 'Count', 'Column', 'Lower Limit', 'Upper Limit'], tablefmt = 'rst', numalign = 'right')\n",
        "  print('Removing Outliers using IQR')\n",
        "  print(table)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GfPGmOvI4f89"
      },
      "outputs": [],
      "source": [
        "column_list = [] # fill this\n",
        "\n",
        "replace_iqr(\n",
        "  dataframe = df,\n",
        "  columns = column_list,\n",
        "  replace = True\n",
        ")\n",
        "df = df.dropna()#'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUeLtiYd4kMs"
      },
      "source": [
        "#### 03.04.02 Using Standard Deviation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gFPjk_Zb4j3m"
      },
      "outputs": [],
      "source": [
        "def std_thres(dataframe, column):\n",
        "  upper_limit = dataframe[column].mean() + 3 * dataframe[column].std()\n",
        "  lower_limit = dataframe[column].mean() - 3 * dataframe[column].std()\n",
        "\n",
        "  return lower_limit, upper_limit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rkImfexs4nbm"
      },
      "outputs": [],
      "source": [
        "def check_outliers_std(dataframe, column):\n",
        "  lower_limit, upper_limit = std_thres(dataframe, column)\n",
        "  if dataframe[(dataframe[column] > upper_limit) | (dataframe[column] < lower_limit)].any(axis = None):\n",
        "    return True\n",
        "  else:\n",
        "    return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gHycsqre4qX6"
      },
      "outputs": [],
      "source": [
        "def replace_std(dataframe, columns, replace = False):\n",
        "  data = []\n",
        "\n",
        "  for column in columns:\n",
        "    if dataframe[column].dtypes == 'int64' or dataframe[column].dtypes == 'float64':\n",
        "      if column != 'Outcome':\n",
        "        outliers_ = check_outliers_std(dataframe, column)\n",
        "        count = None\n",
        "        lower_limit, upper_limit = std_thres(dataframe, column)\n",
        "\n",
        "        if outliers_:\n",
        "          count = dataframe[(dataframe[column] > upper_limit) | (dataframe[column] < lower_limit)][column].count()\n",
        "          if replace:\n",
        "            if lower_limit < 0:\n",
        "              dataframe.loc[(dataframe[column] > upper_limit), column] = np.nan\n",
        "            else:\n",
        "              dataframe.loc[(dataframe[column] < lower_limit), column] = np.nan\n",
        "              dataframe.loc[(dataframe[column] > upper_limit), column] = np.nan\n",
        "        outliers_status = check_outliers_std(dataframe, column)\n",
        "        data.append([outliers_, outliers_status, count, column, lower_limit, upper_limit])\n",
        "\n",
        "  table = tabulate(data, headers = ['Outlier (Previously)', 'Outliers', 'Count', 'Column', 'Lower Limit', 'Upper Limit'], tablefmt = 'rst', numalign = 'right')\n",
        "  print('Removing Outliers using 3 Standard Deviation')\n",
        "  print(table)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D_pvh2IL4q2I"
      },
      "outputs": [],
      "source": [
        "column_list = [] # fill this\n",
        "\n",
        "replace_std(\n",
        "  dataframe = df,\n",
        "  columns = column_list,\n",
        "  replace = True\n",
        ")\n",
        "df = df.dropna()#'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEqxjPOT4vTP"
      },
      "source": [
        "### 03.05 Handling Missing / Zeros / Null\n",
        "##### Filling missing value (numerical only) is better using median than mean or mode"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVpvT5IV4zdY"
      },
      "source": [
        "#### 03.05.01 Detecting Zero Value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "is7a1I744wMK"
      },
      "outputs": [],
      "source": [
        "zero_columns = [] # fill this\n",
        "\n",
        "for x in df.columns:\n",
        "  if df[x].dtypes == 'int64' or df[x].dtypes == 'float64':\n",
        "    if (df[x] == 0).sum() != 0:\n",
        "      print(x, ':', str((df[x] == 0).sum()))\n",
        "      zero_columns.append(x)\n",
        "\n",
        "zero_columns #'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2yFMHRf43pd"
      },
      "source": [
        "#### 03.05.02 Detecting Nan / Non Available Value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PYM4yhj844Ix"
      },
      "outputs": [],
      "source": [
        "nan_columns = [] # fill this\n",
        "\n",
        "for x in df.columns:\n",
        "  if df[x].dtypes == 'object':\n",
        "    if (df[x] == np.nan).sum() or (df[x] == '-').sum() != 0:\n",
        "      print(x, ':', str((df[x] == np.nan).sum()))\n",
        "      nan_columns.append(x)\n",
        "\n",
        "nan_columns #'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w81kHjrH49xD"
      },
      "source": [
        "#### 03.05.03 Replacing Zero with Mean (for numerical value if median value == 0), if necessary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nLz--vIY5BzU"
      },
      "outputs": [],
      "source": [
        "'''column_list = [] # fill this\n",
        "\n",
        "df = df.replace(0, np.nan)\n",
        "\n",
        "for x in column_list:\n",
        "  df[x] = df[x].fillna(df[x].mean()) #'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBWAP-1J5Eyi"
      },
      "source": [
        "#### 03.05.04 Replacing Zero with Median (for numerical value if median value != 0), if necessary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oMvEl4xs5HWd"
      },
      "outputs": [],
      "source": [
        "'''column_list = [] # fill this\n",
        "\n",
        "df = df.replace(0, np.nan)\n",
        "\n",
        "for x in column_list:\n",
        "  df[x] = df[x].fillna(df[x].median()) #'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dog2-5ML5JQ6"
      },
      "source": [
        "#### 03.05.05 Replacing Zero with Mode (for categorical / object value), if necessary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dut4TUuq5NHK"
      },
      "outputs": [],
      "source": [
        "'''column_list = [] # fill this\n",
        "\n",
        "df = df.replace(0, np.nan)\n",
        "\n",
        "for x in column_list:\n",
        "  df[x] = df[x].fillna(df[x].mode()) #'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtFcqtOW5JNo"
      },
      "source": [
        "### 03.06 Handling Incomplete Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-9FaTrv5RlN"
      },
      "source": [
        "### 03.07 Handling Data Biases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8cfMYC15Uw3"
      },
      "source": [
        "### 03.08 Handling Duplicates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vSryzaSI5bNc"
      },
      "outputs": [],
      "source": [
        "#df = df.drop_duplicates()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sx0xbr3K5YLO"
      },
      "source": [
        "##### Data Distribution Check (After)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bA713Qoi5drf"
      },
      "outputs": [],
      "source": [
        "'''x = 'current_month_debit' # replace this\n",
        "y = 'current_month_balance' # replace this\n",
        "color = 'occupation' # replace this\n",
        "\n",
        "fig = px.histogram(\n",
        "  df,\n",
        "  x = x,\n",
        "  y = y,\n",
        "  color = color,\n",
        "  marginal = 'box',\n",
        "  hover_data = df.columns\n",
        ")\n",
        "\n",
        "fig.show() #'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RD2kIuYlgkRm"
      },
      "outputs": [],
      "source": [
        "'''x = 'current_month_debit' # replace this\n",
        "y = 'current_month_balance' # replace this\n",
        "color = 'occupation' # replace this\n",
        "\n",
        "fig = px.scatter(\n",
        "  df,\n",
        "  x = x,\n",
        "  y = y,\n",
        "  color = color,\n",
        "  marginal_x = 'histogram',\n",
        "  marginal_y = 'box',\n",
        "  hover_data = df.columns\n",
        ")\n",
        "\n",
        "fig.show() #'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1O3I_gU5p20"
      },
      "source": [
        "## 04 Enriching Data\n",
        "#### take other dataset, inside or outside from related dataset / business"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oiJULi5g1_a0"
      },
      "outputs": [],
      "source": [
        "'''location = 'Country' # replace this\n",
        "\n",
        "a = df[location].unique()\n",
        "b = gdf[location].unique()\n",
        "\n",
        "for i in a:\n",
        "  if i not in b:\n",
        "    print(i)\n",
        "\n",
        "print(50 * '=')\n",
        "\n",
        "for i in b:\n",
        "  if i not in a:\n",
        "    print(i) #'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7gZKqurz2DCs"
      },
      "outputs": [],
      "source": [
        "value_dict = {}\n",
        "\n",
        "try:\n",
        "  df[location] = df[location].replace(value_dict)\n",
        "except:\n",
        "  pass #'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9z-glw4U5r3Y"
      },
      "source": [
        "## 05 Data Validation\n",
        "#### Verifying consistency, quality, and security of data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXJgoIwCoisk"
      },
      "source": [
        "## 06 Exploration Data Analysis (Univariate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ICAXeqSDopgs"
      },
      "outputs": [],
      "source": [
        "data_profile = ProfileReport(\n",
        "  df,\n",
        "  correlations = {\n",
        "    'pearson' : {'calculate' : True},\n",
        "    'spearman' : {'calculate' : True},\n",
        "    'kendall' : {'calculate' : True},\n",
        "    'phi_k' : {'calculate' : True},\n",
        "    'cramers': {'calculate' : True},\n",
        "  },\n",
        ")\n",
        "\n",
        "data_profile #'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-cKf7u2fYR8"
      },
      "source": [
        "## 07 Select Variable X & Y | Splitting Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62vYCe3x4YmZ"
      },
      "source": [
        "#### 07.01 Data Balancing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zWLslMYI4lnm"
      },
      "outputs": [],
      "source": [
        "'''# Check Before Data Balancing\n",
        "y_var = 'HeartDisease'\n",
        "\n",
        "fig, ax = plt.subplots(figsize = (5, 5))\n",
        "sizes = [count for count in df[y_var].value_counts()]\n",
        "labels = list(df[y_var].value_counts().index)\n",
        "\n",
        "ax.pie(\n",
        "  x = sizes,\n",
        "  labels = labels,\n",
        "  autopct = '%1.1f%%',\n",
        ")\n",
        "plt.show() #'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nijbkHEP4svK"
      },
      "outputs": [],
      "source": [
        "'''n = 20000\n",
        "append_data = []\n",
        "\n",
        "for i in df[y_var].unique():\n",
        "  df_x = df[df[y_var] == i][:n]\n",
        "  append_data.append(df_x)\n",
        "\n",
        "append_df = pd.concat(append_data)\n",
        "append_df.shape #'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aE08oGEy4w8r"
      },
      "outputs": [],
      "source": [
        "'''# Check After Data Balancing\n",
        "\n",
        "fig, ax = plt.subplots(figsize = (5, 5))\n",
        "sizes = [count for count in append_df[y_var].value_counts()]\n",
        "labels = list(append_df[y_var].value_counts().index)\n",
        "\n",
        "ax.pie(\n",
        "  x = sizes,\n",
        "  labels = labels,\n",
        "  autopct = '%1.1f%%',\n",
        ")\n",
        "plt.show() #'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r0TzakFx4zOT"
      },
      "outputs": [],
      "source": [
        "#df = append_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvlFdORoEBsK"
      },
      "source": [
        "### 07.02 Label Encoding / One Hot Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0xalcRFbECSh"
      },
      "outputs": [],
      "source": [
        "df.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_HpZe6myEEaa"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wg80oyDcEF_A"
      },
      "outputs": [],
      "source": [
        "columns = ['gender', 'occupation']\n",
        "\n",
        "for column in columns:\n",
        "  df[column] = df[column].astype('str')\n",
        "  print(df[column].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "evGCZa5KEH08"
      },
      "outputs": [],
      "source": [
        "label_encoders = {}\n",
        "\n",
        "for column in columns:\n",
        "  le = LabelEncoder()\n",
        "  df[column] = le.fit_transform(df[column])\n",
        "  label_encoders[column] = le\n",
        "\n",
        "for column in columns:\n",
        "  labels = label_encoders[column].classes_\n",
        "  print(column)\n",
        "  print('-' * 50)\n",
        "  for i in range(len(labels)):\n",
        "    print(str(i), ':', labels[i])\n",
        "  print('=' * 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_1vko8Gqthp"
      },
      "source": [
        "### 07.03 Define X & Y variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kooq8RzzhsA7"
      },
      "outputs": [],
      "source": [
        "df.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nEFQuk8tvpMK"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bePtz4z4rFd_"
      },
      "outputs": [],
      "source": [
        "x_var = [\n",
        "  'age',\n",
        "  'gender',\n",
        "  'dependents',\n",
        "  'dependents',\n",
        "  'occupation',\n",
        "  'customer_nw_category',\n",
        "  'current_balance',\n",
        "  'previous_month_end_balance',\n",
        "  'average_monthly_balance_prevQ',\n",
        "  'average_monthly_balance_prevQ2',\n",
        "  'current_month_credit',\n",
        "  'previous_month_credit',\n",
        "  'current_month_debit',\n",
        "  'previous_month_debit',\n",
        "  'current_month_balance',\n",
        "  'previous_month_balance'\n",
        "]\n",
        "#x_var = df.columns[1:]\n",
        "y_var = ['churn']\n",
        "#y_var = df.columns[0]\n",
        "\n",
        "x = df[x_var]\n",
        "y = df[y_var]\n",
        "\n",
        "sel_var = y_var + x_var\n",
        "#df = df[sel_var]\n",
        "df.head(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_BVufTarKTH"
      },
      "source": [
        "### 07.04 Split Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "592JuZgZ9eHJ"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)\n",
        "\n",
        "print('x_train shape :', x_train.shape)\n",
        "print('x_test shape :', x_test.shape)\n",
        "print('=' * 50)\n",
        "print('y_train shape :', y_train.shape)\n",
        "print('y_test shape :', y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fO0BqwOanfSs"
      },
      "source": [
        "## 08 Building Machine Learning Model\n",
        "https://www.geeksforgeeks.org/types-of-machine-learning/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAnQmuaXTSf8"
      },
      "source": [
        "### 08.01 Supervised Machine Learning\n",
        "meaning = y variable already available from dataset / “Labelled Dataset”"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3idAplmr-kH"
      },
      "source": [
        "#### 08.01.01 Classification\n",
        "predicting categorical target variables, which represent discrete classes or labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eaTQAp-oToM"
      },
      "source": [
        "##### 08.01.01.01 Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PljssNTbmc9w"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iwE-5Ct9-ty1"
      },
      "outputs": [],
      "source": [
        "def lr(x_train, y_train, x_test, y_test, save = False, matrix = False, unmatch = False):\n",
        "  try:\n",
        "    title = 'Logistic Regression Model'\n",
        "    model = LogisticRegression()\n",
        "    train = model.fit(x_train, y_train)\n",
        "    y_predicted = model.predict(x_test)\n",
        "    training_score = model.score(x_train, y_train)\n",
        "    testing_score = model.score(x_test, y_test)\n",
        "\n",
        "    print('=' * 100)\n",
        "    print(title)\n",
        "    print('=' * 100)\n",
        "    print('Training Score : ', str(round(training_score * 100, 2)), '%')\n",
        "    #print('Regression Coefficient :', str(train.coef_))\n",
        "    #print('Regression Interception :', str(train.intercept_))\n",
        "    print('Testing Score : ', str(round(testing_score * 100, 2)), '%')\n",
        "    print('=' * 100)\n",
        "    print('Classification Report\\n', classification_report(y_test, y_predicted))\n",
        "    print('=' * 100)\n",
        "\n",
        "    if save == True:\n",
        "      with open(title + '.sav', 'wb') as f:\n",
        "        pickle.dump(train, f)\n",
        "        print(title, 'has been saved')\n",
        "        print('=' * 100)\n",
        "    else:\n",
        "      pass\n",
        "\n",
        "    if matrix == True:\n",
        "      cm = confusion_matrix(y_test, y_predicted)\n",
        "\n",
        "      print('Confusion Matrix')\n",
        "      plt.figure(figsize = (5, 3))\n",
        "      sns.heatmap(cm, annot = True, fmt = 'd')\n",
        "      plt.xlabel('Predicted')\n",
        "      plt.ylabel('Actual')\n",
        "      plt.show()\n",
        "    else:\n",
        "      pass\n",
        "\n",
        "    if unmatch == True:\n",
        "      print('=' * 100)\n",
        "      print('Unmatched Prediction Result')\n",
        "      print('-' * 100)\n",
        "      for i in range(0, len(y)):\n",
        "        if y_predicted[i] != y[i]:\n",
        "          print ('Predicted : {0}\\nActual: {1}\\n'.format(y_predicted[i], y[i]))\n",
        "    else:\n",
        "      pass\n",
        "  except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0vPS57LbCPi7"
      },
      "outputs": [],
      "source": [
        "lr(x_train, y_train, x_test, y_test, save = False, matrix = True, unmatch = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gq65PbBSs-Mr"
      },
      "source": [
        "##### 08.01.01.02 Support Vector Machine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "izsfbiUgG8U2"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-1_zw6vpHHeg"
      },
      "outputs": [],
      "source": [
        "def svm(x_train, y_train, x_test, y_test, save = False, matrix = False, unmatch = False):\n",
        "  try:\n",
        "    title = 'Support Vector Machine Model'\n",
        "    model = SVC()\n",
        "    train = model.fit(x_train, y_train)\n",
        "    y_predicted = model.predict(x_test)\n",
        "    training_score = model.score(x_train, y_train)\n",
        "    testing_score = model.score(x_test, y_test)\n",
        "\n",
        "    print('=' * 100)\n",
        "    print(title)\n",
        "    print('=' * 100)\n",
        "    print('Training Score : ', str(round(training_score * 100, 2)), '%')\n",
        "    print('Testing Score : ', str(round(testing_score * 100, 2)), '%')\n",
        "    print('=' * 100)\n",
        "    print('Classification Report\\n', classification_report(y_test, y_predicted))\n",
        "    print('=' * 100)\n",
        "\n",
        "    if save == True:\n",
        "      with open(title + '.sav', 'wb') as f:\n",
        "        pickle.dump(train, f)\n",
        "        print(title, 'has been saved')\n",
        "        print('=' * 100)\n",
        "    else:\n",
        "      pass\n",
        "\n",
        "    if matrix == True:\n",
        "      cm = confusion_matrix(y_test, y_predicted)\n",
        "\n",
        "      print('Confusion Matrix')\n",
        "      plt.figure(figsize = (5, 3))\n",
        "      sns.heatmap(cm, annot = True, fmt = 'd')\n",
        "      plt.xlabel('Predicted')\n",
        "      plt.ylabel('Actual')\n",
        "      plt.show()\n",
        "    else:\n",
        "      pass\n",
        "\n",
        "    if unmatch == True:\n",
        "      print('=' * 100)\n",
        "      print('Unmatched Prediction Result')\n",
        "      print('-' * 100)\n",
        "      for i in range(0, len(y)):\n",
        "        if y_predicted[i] != y[i]:\n",
        "          print ('Predicted : {0}\\nActual: {1}\\n'.format(y_predicted[i], y[i]))\n",
        "    else:\n",
        "      pass\n",
        "  except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t4bGzUliHTLQ"
      },
      "outputs": [],
      "source": [
        "svm(x_train, y_train, x_test, y_test, save = False, matrix = True, unmatch = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoSYjFngtCjb"
      },
      "source": [
        "##### 08.01.01.03 Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_ETcLtFqonP"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DKdifQGlHi37"
      },
      "outputs": [],
      "source": [
        "def rf(x_train, y_train, x_test, y_test, save = False, matrix = False, unmatch = False):\n",
        "  try:\n",
        "    title = 'Random Forest Model'\n",
        "    model = RandomForestClassifier()\n",
        "    train = model.fit(x_train, y_train)\n",
        "    y_predicted = model.predict(x_test)\n",
        "    training_score = model.score(x_train, y_train)\n",
        "    testing_score = model.score(x_test, y_test)\n",
        "\n",
        "    print('=' * 100)\n",
        "    print(title)\n",
        "    print('=' * 100)\n",
        "    print('Training Score : ', str(round(training_score * 100, 2)), '%')\n",
        "    print('Testing Score : ', str(round(testing_score * 100, 2)), '%')\n",
        "    print('=' * 100)\n",
        "    print('Classification Report\\n', classification_report(y_test, y_predicted))\n",
        "    print('=' * 100)\n",
        "\n",
        "    if save == True:\n",
        "      with open(title + '.sav', 'wb') as f:\n",
        "        pickle.dump(train, f)\n",
        "        print(title, 'has been saved')\n",
        "        print('=' * 100)\n",
        "    else:\n",
        "      pass\n",
        "\n",
        "    if matrix == True:\n",
        "      cm = confusion_matrix(y_test, y_predicted)\n",
        "\n",
        "      print('Confusion Matrix')\n",
        "      plt.figure(figsize = (5, 3))\n",
        "      sns.heatmap(cm, annot = True, fmt = 'd')\n",
        "      plt.xlabel('Predicted')\n",
        "      plt.ylabel('Actual')\n",
        "      plt.show()\n",
        "    else:\n",
        "      pass\n",
        "\n",
        "    if unmatch == True:\n",
        "      print('=' * 100)\n",
        "      print('Unmatched Prediction Result')\n",
        "      print('-' * 100)\n",
        "      for i in range(0, len(y)):\n",
        "        if y_predicted[i] != y[i]:\n",
        "          print ('Predicted : {0}\\nActual: {1}\\n'.format(y_predicted[i], y[i]))\n",
        "    else:\n",
        "      pass\n",
        "  except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v36n8WwYHu75"
      },
      "outputs": [],
      "source": [
        "rf(x_train, y_train, x_test, y_test, save = False, matrix = True, unmatch = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wR1TjMmN34BW"
      },
      "source": [
        "##### 08.01.01.04 Decision Tree Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4dWdIiuS37dW"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier, export_graphviz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FqZnEWqvH6zd"
      },
      "outputs": [],
      "source": [
        "def dtc(x_train, y_train, x_test, y_test, save = False, matrix = False, unmatch = False):\n",
        "  try:\n",
        "    title = 'Decision Tree Classifier Model'\n",
        "    model = DecisionTreeClassifier()\n",
        "    train = model.fit(x_train, y_train)\n",
        "    y_predicted = model.predict(x_test)\n",
        "    training_score = model.score(x_train, y_train)\n",
        "    testing_score = model.score(x_test, y_test)\n",
        "\n",
        "    print('=' * 100)\n",
        "    print(title)\n",
        "    print('=' * 100)\n",
        "    print('Training Score : ', str(round(training_score * 100, 2)), '%')\n",
        "    print('Testing Score : ', str(round(testing_score * 100, 2)), '%')\n",
        "    print('=' * 100)\n",
        "    print('Classification Report\\n', classification_report(y_test, y_predicted))\n",
        "    print('=' * 100)\n",
        "\n",
        "    if save == True:\n",
        "      with open(title + '.sav', 'wb') as f:\n",
        "        pickle.dump(train, f)\n",
        "        print(title, 'has been saved')\n",
        "        print('=' * 100)\n",
        "    else:\n",
        "      pass\n",
        "\n",
        "    if matrix == True:\n",
        "      cm = confusion_matrix(y_test, y_predicted)\n",
        "\n",
        "      print('Confusion Matrix')\n",
        "      plt.figure(figsize = (5, 3))\n",
        "      sns.heatmap(cm, annot = True, fmt = 'd')\n",
        "      plt.xlabel('Predicted')\n",
        "      plt.ylabel('Actual')\n",
        "      plt.show()\n",
        "    else:\n",
        "      pass\n",
        "\n",
        "    if unmatch == True:\n",
        "      print('=' * 100)\n",
        "      print('Unmatched Prediction Result')\n",
        "      print('-' * 100)\n",
        "      for i in range(0, len(y)):\n",
        "        if y_predicted[i] != y[i]:\n",
        "          print ('Predicted : {0}\\nActual: {1}\\n'.format(y_predicted[i], y[i]))\n",
        "    else:\n",
        "      pass\n",
        "  except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dlpriy2mIJHQ"
      },
      "outputs": [],
      "source": [
        "dtc(x_train, y_train, x_test, y_test, save = False, matrix = True, unmatch = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DWO5FP65wVc"
      },
      "source": [
        "##### 08.01.01.05 K-Nearest Neighbors (KNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c_p3LB4D50Z4"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iF35an0gQCt2"
      },
      "outputs": [],
      "source": [
        "def knn(x_train, y_train, x_test, y_test, save = False, matrix = False, unmatch = False):\n",
        "  try:\n",
        "    title = 'K-Nearest Neighbors Model'\n",
        "    model = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
        "    sc = StandardScaler()\n",
        "    x_train_sc = sc.fit_transform(x_train)\n",
        "    x_test_sc = sc.transform(x_test)\n",
        "\n",
        "    train = model.fit(x_train_sc, y_train)\n",
        "    y_predicted = model.predict(x_test_sc)\n",
        "    training_score = model.score(x_train_sc, y_train)\n",
        "    testing_score = model.score(x_test_sc, y_test)\n",
        "\n",
        "    print('=' * 100)\n",
        "    print(title)\n",
        "    print('=' * 100)\n",
        "    print('Training Score : ', str(round(training_score * 100, 2)), '%')\n",
        "    print('Testing Score : ', str(round(testing_score * 100, 2)), '%')\n",
        "    print('=' * 100)\n",
        "    print('Classification Report\\n', classification_report(y_test, y_predicted))\n",
        "    print('=' * 100)\n",
        "\n",
        "    if save == True:\n",
        "      with open(title + '.sav', 'wb') as f:\n",
        "        pickle.dump(train, f)\n",
        "        print(title, 'has been saved')\n",
        "        print('=' * 100)\n",
        "    else:\n",
        "      pass\n",
        "\n",
        "    if matrix == True:\n",
        "      cm = confusion_matrix(y_test, y_predicted)\n",
        "\n",
        "      print('Confusion Matrix')\n",
        "      plt.figure(figsize = (5, 3))\n",
        "      sns.heatmap(cm, annot = True, fmt = 'd')\n",
        "      plt.xlabel('Predicted')\n",
        "      plt.ylabel('Actual')\n",
        "      plt.show()\n",
        "    else:\n",
        "      pass\n",
        "\n",
        "    if unmatch == True:\n",
        "      print('=' * 100)\n",
        "      print('Unmatched Prediction Result')\n",
        "      print('-' * 100)\n",
        "      for i in range(0, len(y)):\n",
        "        if y_predicted[i] != y[i]:\n",
        "          print ('Predicted : {0}\\nActual: {1}\\n'.format(y_predicted[i], y[i]))\n",
        "    else:\n",
        "      pass\n",
        "  except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRyDB7G_QsRJ"
      },
      "outputs": [],
      "source": [
        "knn(x_train, y_train, x_test, y_test, save = False, matrix = True, unmatch = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31XiJUQK6MDn"
      },
      "source": [
        "##### 08.01.01.06 Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XAkNXF1169O_"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import GaussianNB, MultinomialNB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "coIpp6mwQ3RD"
      },
      "outputs": [],
      "source": [
        "def nb(x_train, y_train, x_test, y_test, save = False, matrix = False, unmatch = False):\n",
        "  try:\n",
        "    title = 'Naive Bayes Model'\n",
        "    model = GaussianNB()\n",
        "    train = model.fit(x_train, y_train)\n",
        "    y_predicted = model.predict(x_test)\n",
        "    training_score = model.score(x_train, y_train)\n",
        "    testing_score = model.score(x_test, y_test)\n",
        "\n",
        "    print('=' * 100)\n",
        "    print(title)\n",
        "    print('=' * 100)\n",
        "    print('Training Score : ', str(round(training_score * 100, 2)), '%')\n",
        "    print('Testing Score : ', str(round(testing_score * 100, 2)), '%')\n",
        "    print('=' * 100)\n",
        "    print('Classification Report\\n', classification_report(y_test, y_predicted))\n",
        "    print('=' * 100)\n",
        "\n",
        "    if save == True:\n",
        "      with open(title + '.sav', 'wb') as f:\n",
        "        pickle.dump(train, f)\n",
        "        print(title, 'has been saved')\n",
        "        print('=' * 100)\n",
        "    else:\n",
        "      pass\n",
        "\n",
        "    if matrix == True:\n",
        "      cm = confusion_matrix(y_test, y_predicted)\n",
        "\n",
        "      print('Confusion Matrix')\n",
        "      plt.figure(figsize = (5, 3))\n",
        "      sns.heatmap(cm, annot = True, fmt = 'd')\n",
        "      plt.xlabel('Predicted')\n",
        "      plt.ylabel('Actual')\n",
        "      plt.show()\n",
        "    else:\n",
        "      pass\n",
        "\n",
        "    if unmatch == True:\n",
        "      print('=' * 100)\n",
        "      print('Unmatched Prediction Result')\n",
        "      print('-' * 100)\n",
        "      for i in range(0, len(y)):\n",
        "        if y_predicted[i] != y[i]:\n",
        "          print ('Predicted : {0}\\nActual: {1}\\n'.format(y_predicted[i], y[i]))\n",
        "    else:\n",
        "      pass\n",
        "  except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8lkuwVrBRG_a"
      },
      "outputs": [],
      "source": [
        "nb(x_train, y_train, x_test, y_test, save = False, matrix = True, unmatch = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZd_76iqsgxt"
      },
      "source": [
        "##### 08.01.01.07 K Fold Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "It-YWKUys0oO"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "kf = KFold(n_splits = 3)\n",
        "folds = StratifiedKFold(n_splits = 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aGs3Bl-8s8wG"
      },
      "outputs": [],
      "source": [
        "def get_score(model, x_train, x_test, y_train, y_test):\n",
        "  model.fit(x_train, y_train)\n",
        "  score = model.score(x_test, y_test)\n",
        "  rounded = str(round(score * 100, 2)) + '%'\n",
        "  return rounded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HX8cZ3CjtFSZ"
      },
      "outputs": [],
      "source": [
        "scores_lr = []\n",
        "scores_svm = []\n",
        "scores_rf = []\n",
        "scores_dtc = []\n",
        "scores_knn = []\n",
        "scores_nb = []\n",
        "\n",
        "try:\n",
        "  for train_index, test_index in kf.split(x):\n",
        "    scores_lr.append(get_score(LogisticRegression(), x_train, x_test, y_train, y_test))\n",
        "    scores_svm.append(get_score(SVC(), x_train, x_test, y_train, y_test))\n",
        "    scores_rf.append(get_score(RandomForestClassifier(), x_train, x_test, y_train, y_test))\n",
        "    scores_dtc.append(get_score(DecisionTreeClassifier(), x_train, x_test, y_train, y_test))\n",
        "    scores_knn.append(get_score(KNeighborsClassifier(), x_train, x_test, y_train, y_test))\n",
        "    scores_nb.append(get_score(GaussianNB(), x_train, x_test, y_train, y_test))\n",
        "except:\n",
        "  pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GwY6itE7R4th"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  print('Logistic Regression Score :', str(scores_lr))\n",
        "  print('Support Vector Machine Score :', str(scores_svm))\n",
        "  print('Random Forest Score :', str(scores_rf))\n",
        "  print('Decision Tree Classifier Score :', str(scores_dtc))\n",
        "  print('K-Nearest Neighbors Score :', str(scores_knn))\n",
        "  print('Naive Bayes Score :', str(scores_nb))\n",
        "except:\n",
        "  pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQS7cYTUvgvB"
      },
      "source": [
        "Other Method (More Simple)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2MHYfKpwV3Tu"
      },
      "outputs": [],
      "source": [
        "scores_lr = []\n",
        "scores_svm = []\n",
        "scores_rf = []\n",
        "scores_dtc = []\n",
        "scores_knn = []\n",
        "scores_nb = []\n",
        "\n",
        "try:\n",
        "  lr = cross_val_score(LogisticRegression(), x, y)\n",
        "  for i in lr:\n",
        "    scores_lr.append(str(round(i * 100, 2)) + '%')\n",
        "\n",
        "  svm = cross_val_score(SVC(), x, y)\n",
        "  for i in svm:\n",
        "    scores_svm.append(str(round(i * 100, 2)) + '%')\n",
        "\n",
        "  rf = cross_val_score(RandomForestClassifier(n_estimators = 15), x, y)\n",
        "  for i in rf:\n",
        "    scores_rf.append(str(round(i * 100, 2)) + '%')\n",
        "\n",
        "  dtc = cross_val_score(DecisionTreeClassifier(), x, y)\n",
        "  for i in dtc:\n",
        "    scores_dtc.append(str(round(i * 100, 2)) + '%')\n",
        "\n",
        "  knn = cross_val_score(KNeighborsClassifier(), x, y)\n",
        "  for i in knn:\n",
        "    scores_knn.append(str(round(i * 100, 2)) + '%')\n",
        "\n",
        "  nb = cross_val_score(GaussianNB(), x, y)\n",
        "  for i in nb:\n",
        "    scores_nb.append(str(round(i * 100, 2)) + '%')\n",
        "except:\n",
        "  pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6StLpq6W2q6"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  print('Logistic Regression Score :', str(scores_lr))\n",
        "  print('Support Vector Machine Score :', str(scores_svm))\n",
        "  print('Random Forest Score :', str(scores_rf))\n",
        "  print('Decision Tree Classifier Score :', str(scores_dtc))\n",
        "  print('K-Nearest Neighbors Score :', str(scores_knn))\n",
        "  print('Naive Bayes Score :', str(scores_nb))\n",
        "except:\n",
        "  pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZrb1SjSBASw"
      },
      "source": [
        "##### 08.01.01.08 Hyper Parameter Tuning\n",
        "below is example with one ML model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9eQd1A2CBZC3"
      },
      "outputs": [],
      "source": [
        "kernels = ['rbf', 'linear']\n",
        "C = [1, 10, 20]\n",
        "avg_scores = {}\n",
        "\n",
        "try:\n",
        "  for kval in kernels:\n",
        "    for cval in C:\n",
        "      cv_scores = cross_val_score(SVC(kernel = kval, C = cval, gamma = 'auto'), x, y, cv = 5)\n",
        "      avg_scores['svm_' + kval + '_' + str(cval)] = np.average(cv_scores)\n",
        "  for key, values in avg_scores.items():\n",
        "      print(f\"{key} : {str(round(values * 100, 2)) + '%'}\")\n",
        "  print('=' * 100)\n",
        "except:\n",
        "  pass #'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBPf79WCBh0z"
      },
      "source": [
        "##### 08.01.01.09 Grid Search\n",
        "below is example with one ML model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x3eGQXyVBjyj"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j8JYGzxmdeoP"
      },
      "outputs": [],
      "source": [
        "def gsc_svm(x, y, params):\n",
        "  try:\n",
        "    model = GridSearchCV(SVC(gamma = 'auto'), params, cv = 5, return_train_score = False)\n",
        "\n",
        "    train = model.fit(x, y)\n",
        "\n",
        "    grid_df = pd.DataFrame(model.cv_results_)\n",
        "    grid_df = grid_df[['param_C', 'param_kernel', 'mean_test_score']]\n",
        "    grid_df = grid_df.sort_values('mean_test_score', ascending = False)\n",
        "    grid_df = grid_df.reset_index(drop = True)\n",
        "    print(grid_df)\n",
        "  except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hM8HUVu6eWxj"
      },
      "outputs": [],
      "source": [
        "params = {\n",
        "  'C' : [1, 10, 20],\n",
        "  'kernel' : ['rbf', 'linear']\n",
        "}\n",
        "\n",
        "gsc_svm(x, y, params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y76zXcr1DJvx"
      },
      "source": [
        "##### 08.01.01.10 Random Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pus4IpDoDEcz"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rIq2a_Tpm9z7"
      },
      "outputs": [],
      "source": [
        "def rsc_svm(x, y, params):\n",
        "  try:\n",
        "    model = RandomizedSearchCV(SVC(gamma = 'auto'), params, cv = 5, return_train_score = False)\n",
        "\n",
        "    train = model.fit(x, y)\n",
        "\n",
        "    grid_df = pd.DataFrame(model.cv_results_)\n",
        "    grid_df = grid_df[['param_C', 'param_kernel', 'mean_test_score']]\n",
        "    grid_df = grid_df.sort_values('mean_test_score', ascending = False)\n",
        "    grid_df = grid_df.reset_index(drop = True)\n",
        "\n",
        "    display(grid_df)\n",
        "  except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JEZ3P5qbnEcC"
      },
      "outputs": [],
      "source": [
        "params = {\n",
        "  'C' : [1, 10, 20],\n",
        "  'kernel' : ['rbf', 'linear']\n",
        "}\n",
        "\n",
        "rsc_svm(x, y, params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAayb_lpEj_M"
      },
      "source": [
        "Other Method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FoJXeEkJDP-m"
      },
      "outputs": [],
      "source": [
        "model_params = {\n",
        "  'logistic_regression' : {\n",
        "    'model' : LogisticRegression(solver = 'liblinear', multi_class = 'auto'),\n",
        "    'params' : {\n",
        "      'C' : [1, 5, 10]\n",
        "    }\n",
        "  },\n",
        "  'support_vector_machine' : {\n",
        "    'model' : SVC(gamma = 'auto'),\n",
        "    'params' : {\n",
        "      'C' : [1, 5, 10],\n",
        "      'kernel' : ['rbf', 'linear']\n",
        "    }\n",
        "  },\n",
        "  'random_forest' : {\n",
        "    'model' : RandomForestClassifier(),\n",
        "    'params' : {\n",
        "      'n_estimators' : [1, 5, 10]\n",
        "    }\n",
        "  },\n",
        "  'decision_tree_classifier' : {\n",
        "    'model' : DecisionTreeClassifier(),\n",
        "    'params' : {\n",
        "      #'C' : [1, 5, 10]\n",
        "    }\n",
        "  },\n",
        "  'k_nearest_neighbors' : {\n",
        "    'model' : KNeighborsClassifier(),\n",
        "    'params' : {\n",
        "      #'C' : [1, 5, 10]\n",
        "    }\n",
        "  },\n",
        "  'naive_bayes' : {\n",
        "    'model' : GaussianNB(),\n",
        "    'params' : {\n",
        "      #'C' : [1, 5, 10]\n",
        "    }\n",
        "  },\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-8KtPMKGoPd2"
      },
      "outputs": [],
      "source": [
        "def gsc(x, y, model_params):\n",
        "  try:\n",
        "    scores = []\n",
        "\n",
        "    for model_name, mp in model_params.items():\n",
        "      model = GridSearchCV(mp['model'], mp['params'], cv = 5, return_train_score = False)\n",
        "      model.fit(x, y)\n",
        "      scores.append({\n",
        "          'model': model_name,\n",
        "          'best_score': model.best_score_,\n",
        "          'best_params': model.best_params_\n",
        "      })\n",
        "\n",
        "    tune_df = pd.DataFrame(scores, columns = ['model', 'best_score', 'best_params'])\n",
        "    tune_df = tune_df.sort_values('best_score', ascending = False)\n",
        "    tune_df = tune_df.reset_index(drop = True)\n",
        "\n",
        "    display(tune_df)\n",
        "  except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pIyN2dYgo7EL"
      },
      "outputs": [],
      "source": [
        "gsc(x, y, model_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eX5Ri_iPHPky"
      },
      "source": [
        "##### 08.01.01.11 Xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_CdIgPPku7hz"
      },
      "outputs": [],
      "source": [
        "def xgb_classier(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    x_test,\n",
        "    y_test,\n",
        "    save = False,\n",
        "    plot = False,\n",
        "    tree = False,\n",
        "    matrix = False,\n",
        "    unmatch = False,\n",
        "    num_round = 20\n",
        "  ):\n",
        "  try:\n",
        "    title = 'XGB Classification Model'\n",
        "    dtrain = xgb.DMatrix(x_train, label = y_train)\n",
        "    dtest = xgb.DMatrix(x_test, label = y_test)\n",
        "\n",
        "    param = {\n",
        "      'max_depth' : 3,  # the maximum depth of each tree\n",
        "      'eta' : 0.3,  # training step\n",
        "      'silent' : 1,  # logging mode - quiet\n",
        "      'objective' : 'multi:softprob',  # error evaluation for multiclass training\n",
        "      'num_class' : 3  # the number of classes that exist in this datset\n",
        "    }\n",
        "\n",
        "    model = xgb.train(param, dtrain, num_round)\n",
        "    preds = model.predict(dtest)\n",
        "    y_predicted = np.asarray([np.argmax(line) for line in preds])\n",
        "\n",
        "    precision_s = precision_score(y_test, y_predicted, average = 'macro')\n",
        "    accuracy_s = accuracy_score(y_test, y_predicted)\n",
        "\n",
        "    print('=' * 100)\n",
        "    print(title)\n",
        "    print('=' * 100)\n",
        "    print('Precision Score : ', str(round(precision_s * 100, 2)), '%')\n",
        "    #print('Regression Coefficient :', str(train.coef_))\n",
        "    #print('Regression Interception :', str(train.intercept_))\n",
        "    print('Accuracy Score : ', str(round(accuracy_s * 100, 2)), '%')\n",
        "    print('=' * 100)\n",
        "    print('Classification Report\\n', classification_report(y_test, y_predicted))\n",
        "    print('=' * 100)\n",
        "\n",
        "    if save == True:\n",
        "      model.dump_model(title + '.txt')\n",
        "    else:\n",
        "      pass\n",
        "\n",
        "    if plot == True:\n",
        "      xgb.plot_importance(model, importance_type = 'gain')\n",
        "    else:\n",
        "      pass\n",
        "\n",
        "    if tree == True:\n",
        "      xgb.plot_tree(model, num_trees = 0)\n",
        "      xgb.plot_tree(model, num_trees = 9, rankdir = 'LR')\n",
        "    else:\n",
        "      pass\n",
        "\n",
        "    if matrix == True:\n",
        "      cm = confusion_matrix(y_test, y_predicted)\n",
        "\n",
        "      print('Confusion Matrix')\n",
        "      plt.figure(figsize = (5, 3))\n",
        "      sns.heatmap(cm, annot = True, fmt = 'd')\n",
        "      plt.xlabel('Predicted')\n",
        "      plt.ylabel('Real')\n",
        "      plt.show()\n",
        "    else:\n",
        "      pass\n",
        "\n",
        "    if unmatch == True:\n",
        "      print('=' * 100)\n",
        "      print('Unmatched Prediction Result')\n",
        "      print('-' * 100)\n",
        "      for i in range(0, len(y)):\n",
        "        if y_predicted[i] != y[i]:\n",
        "          print ('Predicted : {0}\\nActual: {1}\\n'.format(y_predicted[i], y[i]))\n",
        "    else:\n",
        "      pass\n",
        "  except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EYnzLcpylt09"
      },
      "outputs": [],
      "source": [
        "xgb_classier(\n",
        "  x_train,\n",
        "  y_train,\n",
        "  x_test,\n",
        "  y_test,\n",
        "  save = False,\n",
        "  plot = True,\n",
        "  tree = True,\n",
        "  matrix = True,\n",
        "  unmatch = False,\n",
        "  num_round = 50\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0da59CEc3lEQ"
      },
      "outputs": [],
      "source": [
        "def xgb_cv(x, y, nfold = 3, num_round = 10, seed = 123):\n",
        "  try:\n",
        "    dmatrix = xgb.DMatrix(data = x, label = y)\n",
        "    params = {\n",
        "      'objective' : 'binary:logistic',\n",
        "      'max_depth' : 3,\n",
        "      'colsample_bytree': 0.5,\n",
        "      'subsample' : 0.75,\n",
        "      'gamma' : 0.25,\n",
        "      'learning_rate' : 0.3,\n",
        "      'reg_alpha' : 0.01\n",
        "    }\n",
        "    df = xgb.cv(dtrain = dmatrix, params = params, nfold = nfold, num_boost_round = num_round, seed = seed)\n",
        "\n",
        "    accuracy= 1 - df['test-logloss-mean'].iloc[-1]\n",
        "    print('XGB Classifier Cross Validation')\n",
        "    print('=' * 100)\n",
        "    print('Baseline Cross Validation Accuracy :', str(round(accuracy * 100, 2)), '%')\n",
        "    print('=' * 100)\n",
        "\n",
        "    display(df)\n",
        "  except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lqekv7Mb5bOx"
      },
      "outputs": [],
      "source": [
        "xgb_cv(x, y, nfold = 3, num_round = 10, seed = 123)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cfQfXSyF_akQ"
      },
      "outputs": [],
      "source": [
        "def xgb_rscv(x, y, params, n_iter = 5):\n",
        "  try:\n",
        "    model = xgb.XGBClassifier(random_state = 123)\n",
        "\n",
        "    xgb_rs = RandomizedSearchCV(\n",
        "      estimator = model,\n",
        "      param_distributions = params,\n",
        "      cv = 3,\n",
        "      n_iter = n_iter,\n",
        "      verbose = 2,\n",
        "      random_state = 123\n",
        "    )\n",
        "    xgb_rs.fit(x, y)\n",
        "\n",
        "    print('=' * 100)\n",
        "    print('XGB Classifier Random Search')\n",
        "    print('=' * 100)\n",
        "    print('Best Parameters Found :', xgb_rs.best_params_)\n",
        "    print('Best Accuracy Found :', str(round(xgb_rs.best_score_ * 100, 2)), '%')\n",
        "  except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dFV-tsuLA76z"
      },
      "outputs": [],
      "source": [
        "params = {\n",
        "  'max_depth' : list((range(3,12))),\n",
        "  'alpha' : [0,0.001, 0.01,0.1,1],\n",
        "  'subsample' : [0.5,0.75,1],\n",
        "  'learning_rate' : np.linspace(0.01,0.5, 10),\n",
        "  'n_estimators' : [10, 25, 40]\n",
        "}\n",
        "\n",
        "xgb_rscv(x, y, params, n_iter = 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNu5tUcvsEie"
      },
      "source": [
        "#### 08.01.02 Regression\n",
        "predicting continuous target variables, which represent numerical values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LIITv_ItT0-"
      },
      "source": [
        "##### 08.01.02.01 Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1laRupz0lzm7"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wCYwqv6_zZdK"
      },
      "outputs": [],
      "source": [
        "def single_lir(x_var, y_var, save = False, graph = False):\n",
        "  for i in x_var:\n",
        "    for j in y_var:\n",
        "      try:\n",
        "        title = 'Linear Regression Model ' + i + ' & ' + j\n",
        "        x = np.array(df[i])\n",
        "        y = np.array(df[j])\n",
        "        x = x.reshape(-1, 1)\n",
        "        model = LinearRegression()\n",
        "        train = model.fit(x, y)\n",
        "        y_predicted = model.predict(x)\n",
        "        training_score = model.score(x, y)\n",
        "\n",
        "        print('=' * 100)\n",
        "        print(title)\n",
        "        print('-' * 100)\n",
        "        print('Training Score : ', str(round(training_score * 100, 2)), '%')\n",
        "        print('Coefficients : ', model.coef_)\n",
        "        print('Mean Squared Error: %.2f' % mean_squared_error(y, y_predicted))\n",
        "        print('Coefficient of Determination: %.2f' % r2_score(y, y_predicted))\n",
        "        print('-' * 100)\n",
        "\n",
        "        if save == True:\n",
        "          with open(title + '.sav', 'wb') as f:\n",
        "            pickle.dump(train, f)\n",
        "            print(title, 'has been saved')\n",
        "            print('=' * 100)\n",
        "        else:\n",
        "          pass\n",
        "\n",
        "        if graph == True:\n",
        "          plt.scatter(x, y, color = 'red')\n",
        "          plt.plot(x, y_predicted, color = 'k')\n",
        "          plt.xlabel(i)\n",
        "          plt.ylabel(j)\n",
        "          plt.show()\n",
        "        else:\n",
        "          pass\n",
        "      except:\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9JOdYo2nz1im"
      },
      "outputs": [],
      "source": [
        "single_lir(x_var, y_var, save = False, graph = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NR7DhVufOlJW"
      },
      "outputs": [],
      "source": [
        "def multi_lir(x_var, y_var, save = False):\n",
        "  try:\n",
        "    title = 'Multi Linear Regression Model'\n",
        "    x = np.array(df[x_var])\n",
        "    y = np.array(df[y_var])\n",
        "    model = LinearRegression()\n",
        "    train = model.fit(x, y)\n",
        "    y_predicted = model.predict(x)\n",
        "    training_score = model.score(x, y)\n",
        "\n",
        "    print('=' * 100)\n",
        "    print(title)\n",
        "    print('-' * 100)\n",
        "    print('Training Score : ', str(round(training_score * 100, 2)), '%')\n",
        "    print('Coefficients : ', model.coef_)\n",
        "    print('Mean Squared Error: %.2f' % mean_squared_error(y, y_predicted))\n",
        "    print('Coefficient of Determination: %.2f' % r2_score(y, y_predicted))\n",
        "    print('-' * 100)\n",
        "\n",
        "    if save == True:\n",
        "      with open(title + '.sav', 'wb') as f:\n",
        "        pickle.dump(train, f)\n",
        "        print(title, 'has been saved')\n",
        "        print('=' * 100)\n",
        "    else:\n",
        "      pass\n",
        "  except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7_6V9FSfPOfd"
      },
      "outputs": [],
      "source": [
        "multi_lir(x_var, y_var, save = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FiBGh42tXbT"
      },
      "source": [
        "##### 08.01.02.02 Polynomial Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XfDbA0wYz2Tk"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_H1YId-kRlc4"
      },
      "outputs": [],
      "source": [
        "def single_pr(x_var, y_var, degree = 5, save = False, graph = False):\n",
        "  for i in x_var:\n",
        "    for j in y_var:\n",
        "      try:\n",
        "        title = 'Polynomial Regression Model ' + i + ' & ' + j\n",
        "        model = LinearRegression()\n",
        "        poly = PolynomialFeatures(degree = degree, include_bias = True)\n",
        "        x = np.array(df[i])\n",
        "        y = np.array(df[j])\n",
        "        x_poly = poly.fit_transform(x.reshape(-1, 1))\n",
        "        train = model.fit(x_poly, y)\n",
        "        y_predicted = model.predict(x_poly)\n",
        "        training_score = model.score(x_poly, y)\n",
        "\n",
        "        print('=' * 100)\n",
        "        print(title)\n",
        "        print('-' * 100)\n",
        "        print('Training Score : ', str(round(training_score * 100, 2)), '%')\n",
        "        print('Coefficients : ', model.coef_)\n",
        "        print('Mean Squared Error: %.2f' % mean_squared_error(y, y_predicted))\n",
        "        print('Coefficient of Determination: %.2f' % r2_score(y, y_predicted))\n",
        "        print('-' * 100)\n",
        "\n",
        "        if save == True:\n",
        "          with open(title + '.sav', 'wb') as f:\n",
        "            pickle.dump(train, f)\n",
        "            print(title, 'has been saved')\n",
        "            print('=' * 100)\n",
        "        else:\n",
        "          pass\n",
        "\n",
        "        if graph == True:\n",
        "          plt.scatter(x, y, color = 'red')\n",
        "          plt.plot(x, y_predicted, color = 'k')\n",
        "          plt.xlabel(i)\n",
        "          plt.ylabel(j)\n",
        "          plt.show()\n",
        "        else:\n",
        "          pass\n",
        "      except:\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OuW6kJiBSYAo"
      },
      "outputs": [],
      "source": [
        "single_pr(x_var, y_var, degree = 5, save = False, graph = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "urESjRfMg_-q"
      },
      "outputs": [],
      "source": [
        "def multi_pr(x_var, y_var, degree = 5, save = False):\n",
        "  try:\n",
        "    title = 'Multi Polynomial Regression Model'\n",
        "    model = LinearRegression()\n",
        "    poly = PolynomialFeatures(degree = degree, include_bias = True)\n",
        "    x = np.array(df[x_var])\n",
        "    y = np.array(df[y_var])\n",
        "    x_poly = poly.fit_transform(x)\n",
        "    train = model.fit(x_poly, y)\n",
        "    y_predicted = model.predict(x_poly)\n",
        "    training_score = model.score(x_poly, y)\n",
        "\n",
        "    print('=' * 100)\n",
        "    print(title)\n",
        "    print('-' * 100)\n",
        "    print('Training Score : ', str(round(training_score * 100, 2)), '%')\n",
        "    print('Coefficients : ', model.coef_)\n",
        "    print('Mean Squared Error: %.2f' % mean_squared_error(y, y_predicted))\n",
        "    print('Coefficient of Determination: %.2f' % r2_score(y, y_predicted))\n",
        "    print('-' * 100)\n",
        "\n",
        "    if save == True:\n",
        "      with open(title + '.sav', 'wb') as f:\n",
        "        pickle.dump(train, f)\n",
        "        print(title, 'has been saved')\n",
        "        print('=' * 100)\n",
        "    else:\n",
        "      pass\n",
        "  except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QYUE_ANNhPMc"
      },
      "outputs": [],
      "source": [
        "multi_pr(x_var, y_var, degree = 5, save = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4H2TqZzqtbmz"
      },
      "source": [
        "##### 08.01.02.03 Lasso Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AUEqz-b1DvPO"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import Lasso"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9nXIcBBVllvY"
      },
      "outputs": [],
      "source": [
        "def single_lar(x_var, y_var, alpha = 0.01, save = False, graph = False):\n",
        "  for i in x_var:\n",
        "    for j in y_var:\n",
        "      try:\n",
        "        title = 'Lasso Regression Model ' + i + ' & ' + j\n",
        "        model = Lasso(alpha = alpha, max_iter = 200, tol = 0.1)\n",
        "        x = np.array(df[i])\n",
        "        y = np.array(df[j])\n",
        "        x = x.reshape(-1, 1)\n",
        "        train = model.fit(x, y)\n",
        "        y_predicted = model.predict(x)\n",
        "        training_score = model.score(x, y)\n",
        "\n",
        "        print('=' * 100)\n",
        "        print(title)\n",
        "        print('-' * 100)\n",
        "        print('Training Score : ', str(round(training_score * 100, 2)), '%')\n",
        "        print('Coefficients : ', model.coef_)\n",
        "        print('Mean Squared Error: %.2f' % mean_squared_error(y, y_predicted))\n",
        "        print('Coefficient of Determination: %.2f' % r2_score(y, y_predicted))\n",
        "        print('-' * 100)\n",
        "\n",
        "        if save == True:\n",
        "          with open(title + '.sav', 'wb') as f:\n",
        "            pickle.dump(train, f)\n",
        "            print(title, 'has been saved')\n",
        "            print('=' * 100)\n",
        "        else:\n",
        "          pass\n",
        "\n",
        "        if graph == True:\n",
        "          plt.scatter(x, y, color = 'red')\n",
        "          plt.plot(x, y_predicted, color = 'k')\n",
        "          plt.xlabel(i)\n",
        "          plt.ylabel(j)\n",
        "          plt.show()\n",
        "        else:\n",
        "          pass\n",
        "      except:\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jfllvvRKmpBW"
      },
      "outputs": [],
      "source": [
        "single_lar(x_var, y_var, alpha = 0.0001, save = False, graph = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qz0YJe4qnwyu"
      },
      "outputs": [],
      "source": [
        "def multi_lar(x_var, y_var, alpha = 0.01, save = False):\n",
        "  try:\n",
        "    title = 'Multi Lasso Regression Model'\n",
        "    model = Lasso(alpha = alpha, max_iter = 200, tol = 0.1)\n",
        "    x = np.array(df[x_var])\n",
        "    y = np.array(df[y_var])\n",
        "    train = model.fit(x, y)\n",
        "    y_predicted = model.predict(x)\n",
        "    training_score = model.score(x, y)\n",
        "\n",
        "    print('=' * 100)\n",
        "    print(title)\n",
        "    print('-' * 100)\n",
        "    print('Training Score : ', str(round(training_score * 100, 2)), '%')\n",
        "    print('Coefficients : ', model.coef_)\n",
        "    print('Mean Squared Error: %.2f' % mean_squared_error(y, y_predicted))\n",
        "    print('Coefficient of Determination: %.2f' % r2_score(y, y_predicted))\n",
        "    print('-' * 100)\n",
        "\n",
        "    if save == True:\n",
        "      with open(title + '.sav', 'wb') as f:\n",
        "        pickle.dump(train, f)\n",
        "        print(title, 'has been saved')\n",
        "        print('=' * 100)\n",
        "    else:\n",
        "      pass\n",
        "  except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aBu-50cXoR7k"
      },
      "outputs": [],
      "source": [
        "multi_lar(x_var, y_var, alpha = 0.01, save = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-P9wvqhtfBs"
      },
      "source": [
        "##### 08.01.02.04 Ridge Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QstFjAUQEQN3"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import Ridge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bit9x3jpo5od"
      },
      "outputs": [],
      "source": [
        "def single_rr(x_var, y_var, alpha = 0.01, save = False, graph = False):\n",
        "  for i in x_var:\n",
        "    for j in y_var:\n",
        "      try:\n",
        "        title = 'Ridge Regression Model ' + i + ' & ' + j\n",
        "        model = Ridge(alpha = alpha, max_iter = 100, tol = 0.1)\n",
        "        x = np.array(df[i])\n",
        "        y = np.array(df[j])\n",
        "        x = x.reshape(-1, 1)\n",
        "        train = model.fit(x, y)\n",
        "        y_predicted = model.predict(x)\n",
        "        training_score = model.score(x, y)\n",
        "\n",
        "        print('=' * 100)\n",
        "        print(title)\n",
        "        print('-' * 100)\n",
        "        print('Training Score : ', str(round(training_score * 100, 2)), '%')\n",
        "        print('Coefficients : ', model.coef_)\n",
        "        print('Mean Squared Error: %.2f' % mean_squared_error(y, y_predicted))\n",
        "        print('Coefficient of Determination: %.2f' % r2_score(y, y_predicted))\n",
        "        print('-' * 100)\n",
        "\n",
        "        if save == True:\n",
        "          with open(title + '.sav', 'wb') as f:\n",
        "            pickle.dump(train, f)\n",
        "            print(title, 'has been saved')\n",
        "            print('=' * 100)\n",
        "        else:\n",
        "          pass\n",
        "\n",
        "        if graph == True:\n",
        "          plt.scatter(x, y, color = 'red')\n",
        "          plt.plot(x, y_predicted, color = 'k')\n",
        "          plt.xlabel(i)\n",
        "          plt.ylabel(j)\n",
        "          plt.show()\n",
        "        else:\n",
        "          pass\n",
        "      except:\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Na7zQR3Wo-rt"
      },
      "outputs": [],
      "source": [
        "single_rr(x_var, y_var, alpha = 0.0001, save = False, graph = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sr4wJ1bQpOq7"
      },
      "outputs": [],
      "source": [
        "def multi_rr(x_var, y_var, alpha = 0.01, save = False):\n",
        "  try:\n",
        "    title = 'Multi Ridge Regression Model'\n",
        "    model = Ridge(alpha = alpha, max_iter = 100, tol = 0.1)\n",
        "    x = np.array(df[x_var])\n",
        "    y = np.array(df[y_var])\n",
        "    train = model.fit(x, y)\n",
        "    y_predicted = model.predict(x)\n",
        "    training_score = model.score(x, y)\n",
        "\n",
        "    print('=' * 100)\n",
        "    print(title)\n",
        "    print('-' * 100)\n",
        "    print('Training Score : ', str(round(training_score * 100, 2)), '%')\n",
        "    print('Coefficients : ', model.coef_)\n",
        "    print('Mean Squared Error: %.2f' % mean_squared_error(y, y_predicted))\n",
        "    print('Coefficient of Determination: %.2f' % r2_score(y, y_predicted))\n",
        "    print('-' * 100)\n",
        "\n",
        "    if save == True:\n",
        "      with open(title + '.sav', 'wb') as f:\n",
        "        pickle.dump(train, f)\n",
        "        print(title, 'has been saved')\n",
        "        print('=' * 100)\n",
        "    else:\n",
        "      pass\n",
        "  except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJkO4uBVpUys"
      },
      "outputs": [],
      "source": [
        "multi_rr(x_var, y_var, alpha = 0.01, save = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2JGgYkZtiee"
      },
      "source": [
        "##### 08.01.02.05 Decision tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2JcjDJ0r2ELd"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0UnpdGYkqe7H"
      },
      "outputs": [],
      "source": [
        "def single_dtr(x_var, y_var, save = False, graph = False):\n",
        "  for i in x_var:\n",
        "    for j in y_var:\n",
        "      try:\n",
        "        title = 'Decision Tree Regressor Model ' + i + ' & ' + j\n",
        "        model = DecisionTreeRegressor(random_state = 0)\n",
        "        x = np.array(df[i])\n",
        "        y = np.array(df[j])\n",
        "        x = x.reshape(-1, 1)\n",
        "        train = model.fit(x, y)\n",
        "        y_predicted = model.predict(x)\n",
        "        training_score = model.score(x, y)\n",
        "\n",
        "        print('=' * 100)\n",
        "        print(title)\n",
        "        print('-' * 100)\n",
        "        print('Training Score : ', str(round(training_score * 100, 2)), '%')\n",
        "        print('Mean Squared Error: %.2f' % mean_squared_error(y, y_predicted))\n",
        "        print('Coefficient of Determination: %.2f' % r2_score(y, y_predicted))\n",
        "        print('-' * 100)\n",
        "\n",
        "        if save == True:\n",
        "          with open(title + '.sav', 'wb') as f:\n",
        "            pickle.dump(train, f)\n",
        "            print(title, 'has been saved')\n",
        "            print('=' * 100)\n",
        "        else:\n",
        "          pass\n",
        "\n",
        "        if graph == True:\n",
        "          plt.scatter(x, y, color = 'red')\n",
        "          plt.plot(x, y_predicted, color = 'k')\n",
        "          plt.xlabel(i)\n",
        "          plt.ylabel(j)\n",
        "          plt.show()\n",
        "        else:\n",
        "          pass\n",
        "      except:\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HXVfNWaFqjmu"
      },
      "outputs": [],
      "source": [
        "single_dtr(x_var, y_var, save = False, graph = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R6da0J-tq_5Q"
      },
      "outputs": [],
      "source": [
        "def multi_dtr(x_var, y_var, alpha = 0.01, save = False):\n",
        "  try:\n",
        "    title = 'Multi Decision Tree Regressor Model'\n",
        "    model = DecisionTreeRegressor(random_state = 0)\n",
        "    x = np.array(df[x_var])\n",
        "    y = np.array(df[y_var])\n",
        "    train = model.fit(x, y)\n",
        "    y_predicted = model.predict(x)\n",
        "    training_score = model.score(x, y)\n",
        "\n",
        "    print('=' * 100)\n",
        "    print(title)\n",
        "    print('-' * 100)\n",
        "    print('Training Score : ', str(round(training_score * 100, 2)), '%')\n",
        "    print('Mean Squared Error: %.2f' % mean_squared_error(y, y_predicted))\n",
        "    print('Coefficient of Determination: %.2f' % r2_score(y, y_predicted))\n",
        "    print('-' * 100)\n",
        "\n",
        "    if save == True:\n",
        "      with open(title + '.sav', 'wb') as f:\n",
        "        pickle.dump(train, f)\n",
        "        print(title, 'has been saved')\n",
        "        print('=' * 100)\n",
        "    else:\n",
        "      pass\n",
        "  except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pFENuIl_rCvn"
      },
      "outputs": [],
      "source": [
        "multi_dtr(x_var, y_var, alpha = 0.01, save = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSJbKc5FtmAs"
      },
      "source": [
        "##### 08.01.02.06 Random Forest Regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ULUk0jta2ltM"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ssj4aNT0sVoS"
      },
      "outputs": [],
      "source": [
        "def single_rfr(x_var, y_var, n_estimators = 10, save = False, graph = False):\n",
        "  for i in x_var:\n",
        "    for j in y_var:\n",
        "      try:\n",
        "        title = 'Random Forest Regressor Model ' + i + ' & ' + j\n",
        "        model = RandomForestRegressor(n_estimators = n_estimators, random_state = 0)\n",
        "        x = np.array(df[i])\n",
        "        y = np.array(df[j])\n",
        "        x = x.reshape(-1, 1)\n",
        "        train = model.fit(x, y)\n",
        "        y_predicted = model.predict(x)\n",
        "        training_score = model.score(x, y)\n",
        "\n",
        "        print('=' * 100)\n",
        "        print(title)\n",
        "        print('-' * 100)\n",
        "        print('Training Score : ', str(round(training_score * 100, 2)), '%')\n",
        "        print('Mean Squared Error: %.2f' % mean_squared_error(y, y_predicted))\n",
        "        print('Coefficient of Determination: %.2f' % r2_score(y, y_predicted))\n",
        "        print('-' * 100)\n",
        "\n",
        "        if save == True:\n",
        "          with open(title + '.sav', 'wb') as f:\n",
        "            pickle.dump(train, f)\n",
        "            print(title, 'has been saved')\n",
        "            print('=' * 100)\n",
        "        else:\n",
        "          pass\n",
        "\n",
        "        if graph == True:\n",
        "          plt.scatter(x, y, color = 'red')\n",
        "          plt.plot(x, y_predicted, color = 'k')\n",
        "          plt.xlabel(i)\n",
        "          plt.ylabel(j)\n",
        "          plt.show()\n",
        "        else:\n",
        "          pass\n",
        "      except:\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yqWeep2jsX6v"
      },
      "outputs": [],
      "source": [
        "single_rfr(x_var, y_var, n_estimators = 10, save = False, graph = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFGxD2eIt365"
      },
      "outputs": [],
      "source": [
        "def multi_rfr(x_var, y_var, n_estimators = 10, save = False):\n",
        "  try:\n",
        "    title = 'Multi Random Forest Regressor Model'\n",
        "    model = RandomForestRegressor(n_estimators = n_estimators, random_state = 0)\n",
        "    x = np.array(df[x_var])\n",
        "    y = np.array(df[y_var])\n",
        "    train = model.fit(x, y)\n",
        "    y_predicted = model.predict(x)\n",
        "    training_score = model.score(x, y)\n",
        "\n",
        "    print('=' * 100)\n",
        "    print(title)\n",
        "    print('-' * 100)\n",
        "    print('Training Score : ', str(round(training_score * 100, 2)), '%')\n",
        "    print('Mean Squared Error: %.2f' % mean_squared_error(y, y_predicted))\n",
        "    print('Coefficient of Determination: %.2f' % r2_score(y, y_predicted))\n",
        "    print('-' * 100)\n",
        "\n",
        "    if save == True:\n",
        "      with open(title + '.sav', 'wb') as f:\n",
        "        pickle.dump(train, f)\n",
        "        print(title, 'has been saved')\n",
        "        print('=' * 100)\n",
        "    else:\n",
        "      pass\n",
        "  except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5NittS9muGDR"
      },
      "outputs": [],
      "source": [
        "multi_rfr(x_var, y_var, n_estimators = 10, save = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PulXIYnyzak6"
      },
      "source": [
        "##### 08.01.02.07 Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "COgm_zvIa5bD"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O1fcIcRjzYBy"
      },
      "outputs": [],
      "source": [
        "model_params = {\n",
        "  'linear_regression' : {\n",
        "    'model' : LinearRegression(),\n",
        "    'params' : {\n",
        "      #'C' : [1, 5, 10]\n",
        "    }\n",
        "  },\n",
        "  'lasso_regression' : {\n",
        "    'model' : Lasso(),\n",
        "    'params' : {\n",
        "      'alpha' : [1, 10, 100],\n",
        "      'max_iter' : [1, 10, 100],\n",
        "      'tol' : [0.1, 0.01]\n",
        "    }\n",
        "  },\n",
        "  'ridge_regression' : {\n",
        "    'model' : Ridge(),\n",
        "    'params' : {\n",
        "      'alpha' : [1, 10, 100],\n",
        "      'max_iter' : [1, 10, 100],\n",
        "      'tol' : [0.1, 0.01]\n",
        "    }\n",
        "  },\n",
        "  'decision_tree_regressor' : {\n",
        "    'model' : DecisionTreeRegressor(),\n",
        "    'params' : {\n",
        "      'random_state' : [0, 42]\n",
        "    }\n",
        "  },\n",
        "  'random_forest_regressor' : {\n",
        "    'model' : RandomForestRegressor(),\n",
        "    'params' : {\n",
        "      'n_estimators' : [1, 5, 10],\n",
        "      'random_state' : [0, 42]\n",
        "    }\n",
        "  },\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_dGZ93v4zh9R"
      },
      "outputs": [],
      "source": [
        "def single_gsc(x_var, y_var, model_params, cv = 5):\n",
        "  try:\n",
        "    scores = []\n",
        "\n",
        "    for i in x_var:\n",
        "      for j in y_var:\n",
        "        x = np.array(df[i])\n",
        "        y = np.array(df[j])\n",
        "        x = x.reshape(-1, 1)\n",
        "\n",
        "        for model_name, mp in model_params.items():\n",
        "          model = GridSearchCV(mp['model'], mp['params'], cv = cv, return_train_score = False)\n",
        "          model.fit(x, y)\n",
        "          scores.append({\n",
        "              'model': model_name + ' ' + i + ' & ' + j,\n",
        "              'best_score': model.best_score_,\n",
        "              'best_params': model.best_params_\n",
        "          })\n",
        "\n",
        "    tune_df = pd.DataFrame(scores, columns = ['model', 'best_score', 'best_params'])\n",
        "    tune_df = tune_df.sort_values('best_score', ascending = False)\n",
        "    tune_df = tune_df.reset_index(drop = True)\n",
        "\n",
        "    display(tune_df)\n",
        "  except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O82kSP_Xzmri"
      },
      "outputs": [],
      "source": [
        "single_gsc(x_var, y_var, model_params, cv = 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jVwE-XVA9Ima"
      },
      "outputs": [],
      "source": [
        "def multi_gsc(x_var, y_var, model_params, cv = 5):\n",
        "  try:\n",
        "    scores = []\n",
        "\n",
        "    x = np.array(df[x_var])\n",
        "    y = np.array(df[y_var])\n",
        "\n",
        "    for model_name, mp in model_params.items():\n",
        "      model = GridSearchCV(mp['model'], mp['params'], cv = 5, return_train_score = False)\n",
        "      model.fit(x, y)\n",
        "      scores.append({\n",
        "          'model': model_name + ' ' + i + ' & ' + j,\n",
        "          'best_score': model.best_score_,\n",
        "          'best_params': model.best_params_\n",
        "      })\n",
        "\n",
        "    tune_df = pd.DataFrame(scores, columns = ['model', 'best_score', 'best_params'])\n",
        "    tune_df = tune_df.sort_values('best_score', ascending = False)\n",
        "    tune_df = tune_df.reset_index(drop = True)\n",
        "\n",
        "    display(tune_df)\n",
        "  except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x2UrQKF_9L5-"
      },
      "outputs": [],
      "source": [
        "multi_gsc(x_var, y_var, model_params, cv = 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwmGlJJRFKaO"
      },
      "source": [
        "##### 08.01.02.08 Xgboost Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eNPsyeF_HkqH"
      },
      "outputs": [],
      "source": [
        "def xgb_single_lir(x_var, y_var, save = False, n_estimators = 10, tree = False):\n",
        "  for i in x_var:\n",
        "    for j in y_var:\n",
        "      try:\n",
        "        title = 'XGB Regression Model ' + i + ' & ' + j\n",
        "        x = np.array(df[i])\n",
        "        y = np.array(df[j])\n",
        "        x = x.reshape(-1, 1)\n",
        "        model = xgb.XGBRegressor(objective = 'reg:linear', n_estimators = n_estimators, seed = 123)\n",
        "        train = model.fit(x, y)\n",
        "        y_predicted = model.predict(x)\n",
        "\n",
        "        print('=' * 100)\n",
        "        print(title)\n",
        "        print('-' * 100)\n",
        "        print('Mean Squared Error: %.2f' % mean_squared_error(y, y_predicted))\n",
        "        print('Coefficient of Determination: %.2f' % r2_score(y, y_predicted))\n",
        "        print('-' * 100)\n",
        "\n",
        "        if save == True:\n",
        "          with open(title + '.sav', 'wb') as f:\n",
        "            pickle.dump(train, f)\n",
        "            print(title, 'has been saved')\n",
        "            print('=' * 100)\n",
        "        else:\n",
        "          pass\n",
        "\n",
        "        if tree == True:\n",
        "          xgb.plot_tree(model, num_trees = 0)\n",
        "          xgb.plot_tree(model, num_trees = 9, rankdir = 'LR')\n",
        "          xgb.plot_importance(model)\n",
        "          plt.show()\n",
        "        else:\n",
        "          pass\n",
        "      except:\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z87oscaRIv-4"
      },
      "outputs": [],
      "source": [
        "xgb_single_lir(x_var, y_var, save = False, n_estimators = 10, tree = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QHvJOJUZJkuo"
      },
      "outputs": [],
      "source": [
        "def xgb_regressor(x_var, y_var, save = False, num_round = 5):\n",
        "  for i in x_var:\n",
        "    for j in y_var:\n",
        "      try:\n",
        "        title = 'XGB Regressor Model ' + i + ' & ' + j\n",
        "        x = np.array(df[i])\n",
        "        y = np.array(df[j])\n",
        "        x = x.reshape(-1, 1)\n",
        "        dmatrix = xgb.DMatrix(data = x, label = y)\n",
        "        params = {\n",
        "          'booster' : 'gblinear',\n",
        "          'objective' : 'reg:linear'\n",
        "        }\n",
        "        model = xgb.train(params = params, dtrain = dmatrix, num_boost_round = num_round)\n",
        "        #y_predicted = model.predict(dmatrix)\n",
        "        preds = model.predict(dmatrix)\n",
        "        y_predicted = np.asarray([np.argmax(line) for line in preds])\n",
        "\n",
        "        print('=' * 100)\n",
        "        print(title)\n",
        "        print('-' * 100)\n",
        "        print('Mean Squared Error: %.2f' % mean_squared_error(y, y_predicted))\n",
        "        print('Coefficient of Determination: %.2f' % r2_score(y, y_predicted))\n",
        "        print('-' * 100)\n",
        "\n",
        "        if save == True:\n",
        "          with open(title + '.sav', 'wb') as f:\n",
        "            pickle.dump(model, f)\n",
        "            print(title, 'has been saved')\n",
        "            print('=' * 100)\n",
        "        else:\n",
        "          pass\n",
        "      except:\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EGpIw3v1L5qh"
      },
      "outputs": [],
      "source": [
        "xgb_regressor(x_var, y_var, save = False, num_round = 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJ4qrds8L_cf"
      },
      "outputs": [],
      "source": [
        "def xgb_regcv_v1(x, y, nfold = 3, num_round = 10, seed = 123):\n",
        "  try:\n",
        "    dmatrix = xgb.DMatrix(data = x, label = y)\n",
        "    params = {\n",
        "      'objective' : 'reg:linear',\n",
        "      'max_depth' : 3,\n",
        "      'colsample_bytree': 0.5,\n",
        "      'subsample' : 0.75,\n",
        "      'gamma' : 0.25,\n",
        "      'learning_rate' : 0.3,\n",
        "      'reg_alpha' : 0.01,\n",
        "    }\n",
        "    df = xgb.cv(dtrain = dmatrix, params = params, nfold = nfold, num_boost_round = num_round, seed = num_round, metrics = 'rmse')\n",
        "\n",
        "    print('XGB Regressor Cross Validation v1')\n",
        "    print('=' * 100)\n",
        "\n",
        "    display(df)\n",
        "  except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B3O7khXqM5xf"
      },
      "outputs": [],
      "source": [
        "xgb_regcv_v1(x, y, nfold = 3, num_round = 10, seed = 123)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MdYPFXOWNEAu"
      },
      "outputs": [],
      "source": [
        "def xgb_regcv_v2(x, y, nfold = 3, num_round = 10, seed = 123):\n",
        "  try:\n",
        "    dmatrix = xgb.DMatrix(data = x, label = y)\n",
        "    params = {\n",
        "      'objective' : 'reg:linear',\n",
        "      'max_depth' : 3,\n",
        "      'colsample_bytree': 0.5,\n",
        "      'subsample' : 0.75,\n",
        "      'gamma' : 0.25,\n",
        "      'learning_rate' : 0.3,\n",
        "      'reg_alpha' : 0.01,\n",
        "      'silent' : 1\n",
        "    }\n",
        "    df = xgb.cv(dtrain = dmatrix, params = params, nfold = nfold, num_boost_round = num_round, seed = num_round, metrics = 'mae')\n",
        "\n",
        "    print('XGB Regressor Cross Validation v2')\n",
        "    print('=' * 100)\n",
        "\n",
        "    display(df)\n",
        "  except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i8iEWaDjNH-u"
      },
      "outputs": [],
      "source": [
        "xgb_regcv_v2(x, y, nfold = 3, num_round = 10, seed = 123)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jm5-O1KCNoJx"
      },
      "outputs": [],
      "source": [
        "def xgb_regcv_v3(x, y, nfold = 3, num_round = 10, seed = 123):\n",
        "  try:\n",
        "    dmatrix = xgb.DMatrix(data = x, label = y)\n",
        "    reg_params = [1, 10, 100]\n",
        "    params = {\n",
        "      'objective' : 'reg:linear',\n",
        "      'max_depth' : 3,\n",
        "      'colsample_bytree': 0.5,\n",
        "      'subsample' : 0.75,\n",
        "      'gamma' : 0.25,\n",
        "      'learning_rate' : 0.3,\n",
        "      'reg_alpha' : 0.01,\n",
        "      'silent' : 1\n",
        "    }\n",
        "\n",
        "    rmses = []\n",
        "    for reg in reg_params:\n",
        "      params['lambda'] = reg\n",
        "      model = xgb.cv(\n",
        "        dtrain = dmatrix,\n",
        "        params = params,\n",
        "        #nfold = nfold,\n",
        "        num_boost_round = num_round,\n",
        "        metrics = 'rmse',\n",
        "        as_pandas = True,\n",
        "        seed = 123\n",
        "      )\n",
        "      rmses.append(model['test-rmse-mean'].tail(1).values[0])\n",
        "\n",
        "    print('XGB Regressor Cross Validation v3')\n",
        "    print('=' * 100)\n",
        "    print('Best RMSE as a Function of l2 :')\n",
        "    print(pd.DataFrame(list(zip(reg_params, rmses)), columns = ['l2', 'rmse']))\n",
        "  except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YzoskhXeOhf6"
      },
      "outputs": [],
      "source": [
        "xgb_regcv_v3(x, y, nfold = 3, num_round = 10, seed = 123)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pGqY6vExPoLM"
      },
      "outputs": [],
      "source": [
        "def xgb_regcv_v4(x, y, nfold = 3, seed = 123):\n",
        "  try:\n",
        "    dmatrix = xgb.DMatrix(data = x, label = y)\n",
        "    num_rounds = [5, 10, 15]\n",
        "    params = {\n",
        "      'objective' : 'reg:linear',\n",
        "      'max_depth' : 3,\n",
        "      'colsample_bytree': 0.5,\n",
        "      'subsample' : 0.75,\n",
        "      'gamma' : 0.25,\n",
        "      'learning_rate' : 0.3,\n",
        "      'reg_alpha' : 0.01,\n",
        "      'silent' : 1\n",
        "    }\n",
        "\n",
        "    rmses = []\n",
        "    for round in num_rounds:\n",
        "      model = xgb.cv(\n",
        "        dtrain = dmatrix,\n",
        "        params = params,\n",
        "        nfold = nfold,\n",
        "        num_boost_round = round,\n",
        "        metrics = 'rmse',\n",
        "        as_pandas = True,\n",
        "        seed = 123\n",
        "      )\n",
        "      rmses.append(model['test-rmse-mean'].tail().values[-1])\n",
        "\n",
        "    print('XGB Regressor Cross Validation v4')\n",
        "    print('=' * 100)\n",
        "    print('Best RMSE on Rounds :')\n",
        "    print(pd.DataFrame(list(zip(num_rounds, rmses)), columns = ['num_boosting_rounds', 'rmse']))\n",
        "  except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lj6LM516QpwF"
      },
      "outputs": [],
      "source": [
        "xgb_regcv_v4(x, y, nfold = 3, seed = 123)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1FhfNsOQynF"
      },
      "outputs": [],
      "source": [
        "def xgb_regcv_v5(x, y, nfold = 3, num_round = 10, seed = 123):\n",
        "  try:\n",
        "    dmatrix = xgb.DMatrix(data = x, label = y)\n",
        "    eta_vals = [0.001, 0.01, 0.1]\n",
        "    params = {\n",
        "      'objective' : 'reg:linear',\n",
        "      'max_depth' : 3,\n",
        "      'colsample_bytree': 0.5,\n",
        "      'subsample' : 0.75,\n",
        "      'gamma' : 0.25,\n",
        "      'learning_rate' : 0.3,\n",
        "      'reg_alpha' : 0.01,\n",
        "      'silent' : 1\n",
        "    }\n",
        "\n",
        "    rmses = []\n",
        "    for curr_val in eta_vals:\n",
        "      params['eta'] = curr_val\n",
        "      model = xgb.cv(\n",
        "        dtrain = dmatrix,\n",
        "        params = params,\n",
        "        nfold = nfold,\n",
        "        num_boost_round = num_round,\n",
        "        metrics = 'rmse',\n",
        "        as_pandas = True,\n",
        "        seed = 123\n",
        "      )\n",
        "      rmses.append(model['test-rmse-mean'].tail().values[-1])\n",
        "\n",
        "    print('XGB Regressor Cross Validation v5')\n",
        "    print('=' * 100)\n",
        "    print('Best RMSE on Rounds :')\n",
        "    print(pd.DataFrame(list(zip(eta_vals, rmses)), columns = ['eta', 'rmse']))\n",
        "  except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BY7qXtRfSf4c"
      },
      "outputs": [],
      "source": [
        "xgb_regcv_v5(x, y, nfold = 3, num_round = 10, seed = 123)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q7kQSYgMShnm"
      },
      "outputs": [],
      "source": [
        "def xgb_regcv_v6(x, y, nfold = 3, num_round = 10, seed = 123):\n",
        "  try:\n",
        "    dmatrix = xgb.DMatrix(data = x, label = y)\n",
        "    max_depths = [2, 5, 10, 20]\n",
        "    params = {\n",
        "      'objective' : 'reg:linear',\n",
        "      'max_depth' : 3,\n",
        "      'colsample_bytree': 0.5,\n",
        "      'subsample' : 0.75,\n",
        "      'gamma' : 0.25,\n",
        "      'learning_rate' : 0.3,\n",
        "      'reg_alpha' : 0.01,\n",
        "      'silent' : 1\n",
        "    }\n",
        "\n",
        "    rmses = []\n",
        "    for curr_val in max_depths:\n",
        "      params['max_depth'] = curr_val\n",
        "      model = xgb.cv(\n",
        "        dtrain = dmatrix,\n",
        "        params = params,\n",
        "        nfold = nfold,\n",
        "        num_boost_round = num_round,\n",
        "        metrics = 'rmse',\n",
        "        as_pandas = True,\n",
        "        seed = 123\n",
        "      )\n",
        "      rmses.append(model['test-rmse-mean'].tail().values[-1])\n",
        "\n",
        "    print('XGB Regressor Cross Validation v6')\n",
        "    print('=' * 100)\n",
        "    print('Best RMSE on Rounds :')\n",
        "    print(pd.DataFrame(list(zip(max_depths, rmses)), columns = ['max_depth', 'rmse']))\n",
        "  except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "flKiwZxuS-1-"
      },
      "outputs": [],
      "source": [
        "xgb_regcv_v6(x, y, nfold = 3, num_round = 10, seed = 123)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwveR8dXTD-1"
      },
      "outputs": [],
      "source": [
        "def xgb_regcv_v7(x, y, nfold = 3, num_round = 10, seed = 123):\n",
        "  try:\n",
        "    dmatrix = xgb.DMatrix(data = x, label = y)\n",
        "    colsample_bytree_vals = [0.1, 0.5, 0.8, 1]\n",
        "    params = {\n",
        "      'objective' : 'reg:linear',\n",
        "      'max_depth' : 3,\n",
        "      'colsample_bytree': 0.5,\n",
        "      'subsample' : 0.75,\n",
        "      'gamma' : 0.25,\n",
        "      'learning_rate' : 0.3,\n",
        "      'reg_alpha' : 0.01,\n",
        "      'silent' : 1\n",
        "    }\n",
        "\n",
        "    rmses = []\n",
        "    for curr_val in colsample_bytree_vals:\n",
        "      params['colsample_bytree'] = curr_val\n",
        "      model = xgb.cv(\n",
        "        dtrain = dmatrix,\n",
        "        params = params,\n",
        "        nfold = nfold,\n",
        "        num_boost_round = num_round,\n",
        "        early_stopping_rounds = 5,\n",
        "        metrics = 'rmse',\n",
        "        as_pandas = True,\n",
        "        seed = 123\n",
        "      )\n",
        "      rmses.append(model['test-rmse-mean'].tail().values[-1])\n",
        "\n",
        "    print('XGB Regressor Cross Validation v7')\n",
        "    print('=' * 100)\n",
        "    print('Best RMSE on Rounds :')\n",
        "    print(pd.DataFrame(list(zip(colsample_bytree_vals, rmses)), columns = ['colsample_bytree', 'rmse']))\n",
        "  except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qk6s0-TuTOgK"
      },
      "outputs": [],
      "source": [
        "xgb_regcv_v7(x, y, nfold = 3, num_round = 10, seed = 123)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bk_rvRojUbr5"
      },
      "outputs": [],
      "source": [
        "def xgb_reg_gscv(x, y, params, cv = 3):\n",
        "  try:\n",
        "    dmatrix = xgb.DMatrix(data = x, label = y)\n",
        "    model = xgb.XGBRegressor()\n",
        "\n",
        "    mse = GridSearchCV(\n",
        "      estimator = model,\n",
        "      param_grid = params,\n",
        "      scoring = 'neg_mean_squared_error',\n",
        "      cv = cv,\n",
        "      verbose = 1\n",
        "    )\n",
        "\n",
        "    mse.fit(x, y)\n",
        "\n",
        "    print('XGB Regressor Random Search')\n",
        "    print('=' * 100)\n",
        "    print('Best Parameters Found : ', mse.best_params_)\n",
        "    print('Lowest RMSE found : ', np.sqrt(np.abs(mse.best_score_)))\n",
        "  except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4Cx006gU4mo"
      },
      "outputs": [],
      "source": [
        "params = {\n",
        "  'colsample_bytree' : [0.3, 0.7],\n",
        "  'n_estimators' : [10, 50],\n",
        "  'max_depth' : [1, 5, 10],\n",
        "  'subsample' : [0.5, 0.75],\n",
        "  'gamma' : [0.5, 0.75],\n",
        "  'learning_rate' : [0.1, 0.3],\n",
        "  'reg_alpha' : [0.01, 0.05],\n",
        "}\n",
        "\n",
        "xgb_reg_gscv(x, y, params, cv = 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1VwCamLXTSdP"
      },
      "outputs": [],
      "source": [
        "def xgb_reg_rscv(x, y, params, cv = 3, n_iter = 5):\n",
        "  try:\n",
        "    dmatrix = xgb.DMatrix(data = x, label = y)\n",
        "    model = xgb.XGBRegressor()\n",
        "\n",
        "    mse = RandomizedSearchCV(\n",
        "      estimator = model,\n",
        "      param_distributions = params,\n",
        "      scoring = 'neg_mean_squared_error',\n",
        "      cv = cv,\n",
        "      n_iter = n_iter,\n",
        "      verbose = 1\n",
        "    )\n",
        "\n",
        "    mse.fit(x, y)\n",
        "\n",
        "    print('XGB Regressor Grid Search')\n",
        "    print('=' * 100)\n",
        "    print('Best Parameters Found : ', mse.best_params_)\n",
        "    print('Lowest RMSE found : ', np.sqrt(np.abs(mse.best_score_)))\n",
        "  except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tHxzN7aBUYyE"
      },
      "outputs": [],
      "source": [
        "params = {\n",
        "  'colsample_bytree' : [0.3, 0.7],\n",
        "  'n_estimators' : [10, 50],\n",
        "  'max_depth' : [1, 5, 10],\n",
        "  'subsample' : [0.5, 0.75],\n",
        "  'gamma' : [0.5, 0.75],\n",
        "  'learning_rate' : [0.1, 0.3],\n",
        "  'reg_alpha' : [0.01, 0.05],\n",
        "}\n",
        "\n",
        "xgb_reg_rscv(x, y, params, cv = 3, n_iter = 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxLFONS2UWOt"
      },
      "source": [
        "### 08.02 Unsupervised Machine Learning\n",
        "algorithm discovers patterns and relationships using unlabeled data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wYyOW-dttPl"
      },
      "source": [
        "#### 08.02.01 Clustering\n",
        "grouping data points into clusters based on their similarity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7o-yHxYet2w1"
      },
      "source": [
        "##### 08.02.01.01 K-Means Clustering algorithm\n",
        "\n",
        "create cluster based on variables, and define how many cluster needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GLfi4-2xx4NS"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkJsWZTK76gY"
      },
      "source": [
        "2 Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s17Jp5xF9d7D"
      },
      "outputs": [],
      "source": [
        "def kmeans_2(var_a, var_b, n_clusters = 3, save = False, graph = False): # how many cluster needed\n",
        "  try:\n",
        "    title = 'K-Means Clustering Model ' + var_a + ' & ' + var_b\n",
        "    model = KMeans(n_clusters = n_clusters, max_iter = 100, random_state = 42)\n",
        "    x = df[[var_a, var_b]]\n",
        "    train = model.fit(x)\n",
        "    y = model.labels_\n",
        "\n",
        "    final_df = x\n",
        "    final_df['cluster'] = y\n",
        "\n",
        "    print('=' * 100)\n",
        "    print(title)\n",
        "    print('=' * 100)\n",
        "    print('K-Means Inertia :', model.inertia_)\n",
        "    print('=' * 100)\n",
        "\n",
        "    if save == True:\n",
        "      with open(title + '.sav', 'wb') as f:\n",
        "        pickle.dump(train, f)\n",
        "        print(title, 'has been saved')\n",
        "        print('=' * 100)\n",
        "    else:\n",
        "      pass\n",
        "\n",
        "    if graph == True:\n",
        "      fig = px.scatter(\n",
        "        final_df,\n",
        "        x = var_a,\n",
        "        y = var_b,\n",
        "        color = final_df.columns[-1]\n",
        "      )\n",
        "      fig.show()\n",
        "    else:\n",
        "      pass\n",
        "  except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EY4mt7bp-Yf7"
      },
      "outputs": [],
      "source": [
        "var_a = 'sepal length (cm)'\n",
        "var_b = 'sepal width (cm)'\n",
        "\n",
        "kmeans_2(var_a, var_b, n_clusters = 3, save = False, graph = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sTnjATEFMFO"
      },
      "source": [
        "More than 2 Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ubjz46-GYa-"
      },
      "outputs": [],
      "source": [
        "def kmeans(x_var, n_clusters = 3, save = False, graph = False): # how many cluster needed\n",
        "  try:\n",
        "    title = 'K-Means Clustering Model'\n",
        "    model = KMeans(n_clusters = n_clusters, max_iter = 100, random_state = 42)\n",
        "    x = df[x_var]\n",
        "    train = model.fit(x)\n",
        "    y = model.labels_\n",
        "\n",
        "    final_df = x\n",
        "    final_df['cluster'] = y\n",
        "\n",
        "    print('=' * 100)\n",
        "    print(title)\n",
        "    print('=' * 100)\n",
        "    print('K-Means Inertia :', model.inertia_)\n",
        "    print('=' * 100)\n",
        "\n",
        "    if save == True:\n",
        "      with open(title + '.sav', 'wb') as f:\n",
        "        pickle.dump(train, f)\n",
        "        print(title, 'has been saved')\n",
        "        print('=' * 100)\n",
        "    else:\n",
        "      pass\n",
        "\n",
        "    if graph == True:\n",
        "      fig = px.scatter_3d(\n",
        "        final_df,\n",
        "        x = final_df.columns[0],\n",
        "        y = final_df.columns[1],\n",
        "        z = final_df.columns[2],\n",
        "        color = final_df.columns[-1]\n",
        "      )\n",
        "      fig.show()\n",
        "    else:\n",
        "      pass\n",
        "  except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7HQAVmBGwY_"
      },
      "outputs": [],
      "source": [
        "x_var = [\n",
        "  'sepal length (cm)',\n",
        "  'sepal width (cm)',\n",
        "  'petal length (cm)',\n",
        "  'petal width (cm)'\n",
        "]\n",
        "\n",
        "kmeans(x_var, n_clusters = 3, save = False, graph = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7n6D4LKst7OM"
      },
      "source": [
        "##### 08.02.01.02 Mean-shift algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "anPCBA_D4YG_"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import MeanShift"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pp_rOwzcyWAJ"
      },
      "outputs": [],
      "source": [
        "def ms_2(var_a, var_b, save = False, graph = False):\n",
        "  try:\n",
        "    title = 'Mean Shift Model ' + var_a + ' & ' + var_b\n",
        "    model = MeanShift()\n",
        "    x = df[[var_a, var_b]]\n",
        "    train = model.fit(x)\n",
        "    y = model.labels_\n",
        "\n",
        "    final_df = x\n",
        "    final_df['cluster'] = y\n",
        "\n",
        "    print('=' * 100)\n",
        "    print(title)\n",
        "    print('=' * 100)\n",
        "    print('Number of Cluster :', len(final_df['cluster'].unique()))\n",
        "    print('=' * 100)\n",
        "    print('Clusters :', final_df['cluster'].unique())\n",
        "    print('=' * 100)\n",
        "\n",
        "    if save == True:\n",
        "      with open(title + '.sav', 'wb') as f:\n",
        "        pickle.dump(train, f)\n",
        "        print(title, 'has been saved')\n",
        "        print('=' * 100)\n",
        "    else:\n",
        "      pass\n",
        "\n",
        "    if graph == True:\n",
        "      fig = px.scatter(\n",
        "        final_df,\n",
        "        x = var_a,\n",
        "        y = var_b,\n",
        "        color = final_df.columns[-1]\n",
        "      )\n",
        "      fig.show()\n",
        "    else:\n",
        "      pass\n",
        "  except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kqTItSAtyZQv"
      },
      "outputs": [],
      "source": [
        "var_a = 'sepal length (cm)'\n",
        "var_b = 'sepal width (cm)'\n",
        "\n",
        "ms_2(var_a, var_b, save = False, graph = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r4zaxGcL68LA"
      },
      "outputs": [],
      "source": [
        "def ms(x_var, save = False, graph = False):\n",
        "  try:\n",
        "    title = 'Mean Shift Model'\n",
        "    model = MeanShift()\n",
        "    x = df[x_var]\n",
        "    train = model.fit(x)\n",
        "    y = model.labels_\n",
        "\n",
        "    final_df = x\n",
        "    final_df['cluster'] = y\n",
        "\n",
        "    print('=' * 100)\n",
        "    print(title)\n",
        "    print('=' * 100)\n",
        "    print('Number of Cluster :', len(final_df['cluster'].unique()))\n",
        "    print('=' * 100)\n",
        "    print('Clusters :', final_df['cluster'].unique())\n",
        "    print('=' * 100)\n",
        "\n",
        "    if save == True:\n",
        "      with open(title + '.sav', 'wb') as f:\n",
        "        pickle.dump(train, f)\n",
        "        print(title, 'has been saved')\n",
        "        print('=' * 100)\n",
        "    else:\n",
        "      pass\n",
        "\n",
        "    if graph == True:\n",
        "      fig = px.scatter_3d(\n",
        "        final_df,\n",
        "        x = final_df.columns[0],\n",
        "        y = final_df.columns[1],\n",
        "        z = final_df.columns[2],\n",
        "        color = final_df.columns[-1]\n",
        "      )\n",
        "      fig.show()\n",
        "    else:\n",
        "      pass\n",
        "  except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kI3BMnB77Da5"
      },
      "outputs": [],
      "source": [
        "x_var = [\n",
        "  'sepal length (cm)',\n",
        "  'sepal width (cm)',\n",
        "  'petal length (cm)',\n",
        "  'petal width (cm)'\n",
        "]\n",
        "\n",
        "ms(x_var, save = False, graph = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBK8pabRuJdO"
      },
      "source": [
        "##### 08.02.01.03 DBSCAN Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7I-jBAm-498G"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import DBSCAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wu-9yqSG8jQC"
      },
      "outputs": [],
      "source": [
        "def dbscan_2(var_a, var_b, eps = 3, min_samples = 5, save = False, graph = False):\n",
        "  try:\n",
        "    title = 'DBSCAN Model ' + var_a + ' & ' + var_b\n",
        "    model = DBSCAN(eps = eps, min_samples = min_samples)\n",
        "    x = df[[var_a, var_b]]\n",
        "    train = model.fit(x)\n",
        "    y = model.labels_\n",
        "\n",
        "    final_df = x\n",
        "    final_df['cluster'] = y\n",
        "\n",
        "    print('=' * 100)\n",
        "    print(title)\n",
        "    print('=' * 100)\n",
        "    print('Number of Cluster :', len(final_df['cluster'].unique()))\n",
        "    print('=' * 100)\n",
        "    print('Clusters :', final_df['cluster'].unique())\n",
        "    print('=' * 100)\n",
        "\n",
        "    if save == True:\n",
        "      with open(title + '.sav', 'wb') as f:\n",
        "        pickle.dump(train, f)\n",
        "        print(title, 'has been saved')\n",
        "        print('=' * 100)\n",
        "    else:\n",
        "      pass\n",
        "\n",
        "    if graph == True:\n",
        "      fig = px.scatter(\n",
        "        final_df,\n",
        "        x = var_a,\n",
        "        y = var_b,\n",
        "        color = final_df.columns[-1]\n",
        "      )\n",
        "      fig.show()\n",
        "    else:\n",
        "      pass\n",
        "  except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kH5axHTX8_so"
      },
      "outputs": [],
      "source": [
        "var_a = 'sepal length (cm)'\n",
        "var_b = 'sepal width (cm)'\n",
        "\n",
        "dbscan_2(var_a, var_b, eps = 3, min_samples = 20, save = False, graph = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OYbR_E_a9B4O"
      },
      "outputs": [],
      "source": [
        "def dbscan(var_a, var_b, eps = 3, min_samples = 5, save = False, graph = False):\n",
        "  try:\n",
        "    title = 'DBSCAN Model ' + var_a + ' & ' + var_b\n",
        "    model = DBSCAN(eps = eps, min_samples = min_samples)\n",
        "    x = df[x_var]\n",
        "    train = model.fit(x)\n",
        "    y = model.labels_\n",
        "\n",
        "    final_df = x\n",
        "    final_df['cluster'] = y\n",
        "\n",
        "    print('=' * 100)\n",
        "    print(title)\n",
        "    print('=' * 100)\n",
        "    print('Number of Cluster :', len(final_df['cluster'].unique()))\n",
        "    print('=' * 100)\n",
        "    print('Clusters :', final_df['cluster'].unique())\n",
        "    print('=' * 100)\n",
        "\n",
        "    if save == True:\n",
        "      with open(title + '.sav', 'wb') as f:\n",
        "        pickle.dump(train, f)\n",
        "        print(title, 'has been saved')\n",
        "        print('=' * 100)\n",
        "    else:\n",
        "      pass\n",
        "\n",
        "    if graph == True:\n",
        "      fig = px.scatter_3d(\n",
        "        final_df,\n",
        "        x = final_df.columns[0],\n",
        "        y = final_df.columns[1],\n",
        "        z = final_df.columns[2],\n",
        "        color = final_df.columns[-1]\n",
        "      )\n",
        "      fig.show()\n",
        "    else:\n",
        "      pass\n",
        "  except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N6IDnBZU9Cjo"
      },
      "outputs": [],
      "source": [
        "x_var = [\n",
        "  'sepal length (cm)',\n",
        "  'sepal width (cm)',\n",
        "  'petal length (cm)',\n",
        "  'petal width (cm)'\n",
        "]\n",
        "\n",
        "dbscan(var_a, var_b, eps = 0.01, min_samples = 20, save = False, graph = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZ0QaGAPuNcl"
      },
      "source": [
        "##### 08.02.01.04 Principal Component Analysis\n",
        "reduce high dimensional data (if x variable contain more than 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zf3MSsMX5bw-"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIaOoyKTizzu"
      },
      "source": [
        "Reduce Variables to 2 / 2 Dimensional"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eytBQLebNznB"
      },
      "outputs": [],
      "source": [
        "def kmeans_pca(x_var, n_components = 2, save = False, graph = False): # how many cluster needed\n",
        "  try:\n",
        "    title = 'K-Means & PCA Clustering Model'\n",
        "    model = KMeans(n_clusters = n_components, max_iter = 100, random_state = 42)\n",
        "    pca = PCA(n_components = n_components)\n",
        "    x = df[x_var]\n",
        "    x = pca.fit_transform(x)\n",
        "    x = scaler.fit_transform(x)\n",
        "    train = model.fit(x)\n",
        "    y = model.labels_\n",
        "\n",
        "    x_pca = model.transform(x)\n",
        "    df_pca = pd.DataFrame(\n",
        "      x_pca,\n",
        "      columns = ['PC{}'.format(i + 1) for i in range(n_components)]\n",
        "    )\n",
        "\n",
        "    print('=' * 100)\n",
        "    print(title)\n",
        "    print('=' * 100)\n",
        "    print('K-Means & PCA Inertia :', model.inertia_)\n",
        "    print('=' * 100)\n",
        "\n",
        "    if save == True:\n",
        "      with open(title + '.sav', 'wb') as f:\n",
        "        pickle.dump(train, f)\n",
        "        print(title, 'has been saved')\n",
        "        print('=' * 100)\n",
        "    else:\n",
        "      pass\n",
        "\n",
        "    if graph == True:\n",
        "      fig = px.scatter(\n",
        "        df_pca,\n",
        "        df_pca.columns[0],\n",
        "        df_pca.columns[1],\n",
        "        color = y\n",
        "      )\n",
        "      fig.show()\n",
        "    else:\n",
        "      pass\n",
        "  except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44mM8teyOZrQ"
      },
      "outputs": [],
      "source": [
        "x_var = [\n",
        "  'sepal length (cm)',\n",
        "  'sepal width (cm)',\n",
        "  'petal length (cm)',\n",
        "  'petal width (cm)'\n",
        "]\n",
        "\n",
        "kmeans_pca(x_var, n_components = 3, save = False, graph = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OvtA4BDjJs1"
      },
      "source": [
        "Reduce Variables to 3 / 3 Dimensional"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yeUGTTBAi8y9"
      },
      "outputs": [],
      "source": [
        "def kmeans_pca_3d(x_var, n_components = 3, save = False, graph = False): # how many cluster needed\n",
        "  try:\n",
        "    title = 'K-Means & PCA Clustering Model'\n",
        "    model = KMeans(n_clusters = n_components, max_iter = 100, random_state = 42)\n",
        "    pca = PCA(n_components = n_components)\n",
        "    x = df[x_var]\n",
        "    x = pca.fit_transform(x)\n",
        "    x = scaler.fit_transform(x)\n",
        "    train = model.fit(x)\n",
        "    y = model.labels_\n",
        "\n",
        "    x_pca = model.transform(x)\n",
        "    df_pca = pd.DataFrame(\n",
        "      x_pca,\n",
        "      columns = ['PC{}'.format(i + 1) for i in range(n_components)]\n",
        "    )\n",
        "\n",
        "    print('=' * 100)\n",
        "    print(title)\n",
        "    print('=' * 100)\n",
        "    print('K-Means & PCA Inertia :', model.inertia_)\n",
        "    print('=' * 100)\n",
        "\n",
        "    if save == True:\n",
        "      with open(title + '.sav', 'wb') as f:\n",
        "        pickle.dump(train, f)\n",
        "        print(title, 'has been saved')\n",
        "        print('=' * 100)\n",
        "    else:\n",
        "      pass\n",
        "\n",
        "    if graph == True:\n",
        "      fig = px.scatter_3d(\n",
        "        df_pca,\n",
        "        x = df_pca.columns[0],\n",
        "        y = df_pca.columns[1],\n",
        "        z = df_pca.columns[2],\n",
        "        color = y\n",
        "      )\n",
        "      fig.show()\n",
        "    else:\n",
        "      pass\n",
        "  except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jvfACrk6jQka"
      },
      "outputs": [],
      "source": [
        "x_var = [\n",
        "  'sepal length (cm)',\n",
        "  'sepal width (cm)',\n",
        "  'petal length (cm)',\n",
        "  'petal width (cm)'\n",
        "]\n",
        "\n",
        "kmeans_pca_3d(x_var, n_components = 4, save = False, graph = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Nh3UR5nuRNW"
      },
      "source": [
        "##### 08.02.01.05 Independent Component Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iU5aBEbe5xYG"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import FastICA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AwsdJcs73hae"
      },
      "outputs": [],
      "source": [
        "def kmeans_ica(x_var, n_components = 2, save = False, graph = False): # how many cluster needed\n",
        "  try:\n",
        "    title = 'K-Means & ICA Clustering Model'\n",
        "    model = KMeans(n_clusters = n_components, max_iter = 100, random_state = 42)\n",
        "    ica = FastICA(n_components = n_components)\n",
        "    x = df[x_var]\n",
        "    x = ica.fit_transform(x)\n",
        "    x = scaler.fit_transform(x)\n",
        "    train = model.fit(x)\n",
        "    y = model.labels_\n",
        "\n",
        "    x_ica = model.transform(x)\n",
        "    df_ica = pd.DataFrame(\n",
        "      x_ica,\n",
        "      columns = ['PC{}'.format(i + 1) for i in range(n_components)]\n",
        "    )\n",
        "\n",
        "    print('=' * 100)\n",
        "    print(title)\n",
        "    print('=' * 100)\n",
        "    print('K-Means & ICA Inertia :', model.inertia_)\n",
        "    print('=' * 100)\n",
        "\n",
        "    if save == True:\n",
        "      with open(title + '.sav', 'wb') as f:\n",
        "        pickle.dump(train, f)\n",
        "        print(title, 'has been saved')\n",
        "        print('=' * 100)\n",
        "    else:\n",
        "      pass\n",
        "\n",
        "    if graph == True:\n",
        "      fig = px.scatter(\n",
        "        df_ica,\n",
        "        df_ica.columns[0],\n",
        "        df_ica.columns[1],\n",
        "        color = y\n",
        "      )\n",
        "      fig.show()\n",
        "    else:\n",
        "      pass\n",
        "  except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-HVnM2l4W8-"
      },
      "outputs": [],
      "source": [
        "x_var = [\n",
        "  'sepal length (cm)',\n",
        "  'sepal width (cm)',\n",
        "  'petal length (cm)',\n",
        "  'petal width (cm)'\n",
        "]\n",
        "\n",
        "kmeans_ica(x_var, n_components = 3, save = False, graph = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BXeALA3y4gl_"
      },
      "outputs": [],
      "source": [
        "def kmeans_ica_3d(x_var, n_components = 3, save = False, graph = False): # how many cluster needed\n",
        "  try:\n",
        "    title = 'K-Means & ICA Clustering Model'\n",
        "    model = KMeans(n_clusters = n_components, max_iter = 100, random_state = 42)\n",
        "    ica = FastICA(n_components = n_components)\n",
        "    x = df[x_var]\n",
        "    x = ica.fit_transform(x)\n",
        "    x = scaler.fit_transform(x)\n",
        "    train = model.fit(x)\n",
        "    y = model.labels_\n",
        "\n",
        "    x_ica = model.transform(x)\n",
        "    df_ica = pd.DataFrame(\n",
        "      x_ica,\n",
        "      columns = ['PC{}'.format(i + 1) for i in range(n_components)]\n",
        "    )\n",
        "\n",
        "    print('=' * 100)\n",
        "    print(title)\n",
        "    print('=' * 100)\n",
        "    print('K-Means & PCA Inertia :', model.inertia_)\n",
        "    print('=' * 100)\n",
        "\n",
        "    if save == True:\n",
        "      with open(title + '.sav', 'wb') as f:\n",
        "        pickle.dump(train, f)\n",
        "        print(title, 'has been saved')\n",
        "        print('=' * 100)\n",
        "    else:\n",
        "      pass\n",
        "\n",
        "    if graph == True:\n",
        "      fig = px.scatter_3d(\n",
        "        df_ica,\n",
        "        x = df_ica.columns[0],\n",
        "        y = df_ica.columns[1],\n",
        "        z = df_ica.columns[2],\n",
        "        color = y\n",
        "      )\n",
        "      fig.show()\n",
        "    else:\n",
        "      pass\n",
        "  except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IiuHFtOj4l_p"
      },
      "outputs": [],
      "source": [
        "x_var = [\n",
        "  'sepal length (cm)',\n",
        "  'sepal width (cm)',\n",
        "  'petal length (cm)',\n",
        "  'petal width (cm)'\n",
        "]\n",
        "\n",
        "kmeans_ica_3d(x_var, n_components = 4, save = False, graph = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2P2fOm2txyd"
      },
      "source": [
        "#### 08.02.02 Association\n",
        "discovering relationships between items in a dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emWVpelguXpm"
      },
      "source": [
        "##### 08.02.02.01 Apriori Algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usgIk8yvuaqn"
      },
      "source": [
        "##### 08.02.02.02 Eclat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeK2QHEUudrm"
      },
      "source": [
        "##### 08.02.02.03 FP-growth Algorithm"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
