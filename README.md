# Autonomous Multi-Agent Research Engine

**A high-throughput, microservice-based architecture for deep domain research, autonomous data analysis, and multi-agent consensus.**

## ğŸ“– Technical Overview

This project is an **Autonomous Agentic System** designed to move beyond simple RAG (Retrieval Augmented Generation) towards **Deep Research**. It utilizes a hierarchical "Supervisor-Worker" architecture where Large Language Models (LLMs) act as architects/planners, while specialized Python sub-systems act as execution tools.

Unlike standard chatbots, this system separates **Reasoning** (LLM) from **Execution** (Code). It features a self-correcting code execution environment, allowing agents to scrape data, build local SQL databases (DuckDB), perform statistical analysis via Pandas/Polars, and generate visualizations programmatically.

### Key Differentiators
*   **Microservices Architecture:** Fully containerized services communicating via REST/gRPC and OpenAPI standards.
*   **Graph-Based Orchestration:** Uses **LangGraph** for cyclic state management (loops, retries, consensus), not linear chains.
*   **Code-First Analysis:** Hallucination reduction by forcing LLMs to write Python code for calculations rather than performing mental math.
*   **Asynchronous Parallelism:** Implements `asyncio` semaphores and batch processing to handle deep web scraping without hitting API rate limits.
*   **Persisted State:** Uses PostgreSQL checkpointers to support long-running research tasks (hours/days) with pause/resume capabilities.

---

## ğŸ— System Architecture

The system follows a **Hub-and-Spoke** microservices pattern.

```mermaid
graph TD
    User[Client / API Consumer] -->|REST Request| Gateway[API Gateway / Nginx]
    
    subgraph "Service Layer"
        Gateway --> Orchestrator[Orchestrator Service<br>(LangGraph + FastAPI)]
        
        Orchestrator -->|HTTP/RPC| ToolService[Tool Execution Service<br>(Sandbox/E2B)]
        Orchestrator -->|HTTP/RPC| RAGService[Domain RAG Service<br>(Qdrant/Weaviate)]
        Orchestrator -->|HTTP/RPC| ScraperService[Web Gathering Service<br>(Tavily/Firecrawl)]
    end
    
    subgraph "Data Layer"
        Orchestrator -->|State Persist| Postgres[(PostgreSQL<br>Graph State)]
        ToolService -->|Analytical Data| DuckDB[(DuckDB<br>Parquet/CSV)]
        RAGService -->|Embeddings| VectorDB[(Vector DB)]
    end
```

### 1. The Orchestrator (The Brain)
*   **Stack:** Python, FastAPI, LangGraph, LiteLLM.
*   **Role:** Receives queries, decomposes them into a DAG (Directed Acyclic Graph) of tasks, and manages the state.
*   **Logic:** Decides *which* tool service to call based on OpenAPI specifications. Handles the "Consensus Loop" where critic agents review worker outputs.

### 2. The Tool Execution Service (The Muscle)
*   **Stack:** Docker / E2B Sandbox, Pandas, Scikit-Learn.
*   **Role:** Safely executes Python code generated by the Orchestrator.
*   **Capabilities:**
    *   Dataframe manipulation (Filtering, Grouping, Correlation).
    *   Financial calculation (ratios, growth rates).
    *   Visualization generation (Plotly/Matplotlib).

### 3. The RAG Service (The Library)
*   **Stack:** LlamaIndex, Qdrant/Weaviate, Cross-Encoders.
*   **Role:** Domain-specific knowledge retrieval.
*   **Pipeline:** Hybrid Search (Keyword + Vector) $\rightarrow$ Re-Ranking (Cohere/BGE) $\rightarrow$ Context Injection.

---

## âš™ï¸ The "Funnel" Workflow

The system utilizes a 3-stage funnel to optimize for cost and accuracy:

1.  **Phase 1: Broad Screening (Code-Heavy)**
    *   *Action:* Python scripts fetch broad datasets (e.g., 2,000 tickers or 500 legal cases).
    *   *Filtering:* Hard-coded filters (e.g., `PBV < 1.0` or `Year > 2020`) reduce the list to ~50 candidates.
    *   *No LLM:* This phase is purely deterministic to save tokens.

2.  **Phase 2: Deep Dive (Agent-Heavy)**
    *   *Action:* The 50 candidates are split into batches (e.g., 5 concurrent agents).
    *   *Parallelism:* Agents trigger sub-routines: News Search + Financial Extraction + Risk Analysis.
    *   *Throttling:* `asyncio.Semaphore` ensures external API rate limits are respected.

3.  **Phase 3: Synthesis & Consensus (Reasoning-Heavy)**
    *   *Action:* Aggregated reports are passed to a "Critic" agent.
    *   *Loop:* If data is missing or contradictory, the Critic rejects the state, triggering a targeted re-fetch loop.
    *   *Final Output:* HTML report generation.

---

### ğŸ§© System Architecture Diagram

```mermaid
%%{init: {'theme': 'base', 'themeVariables': { 'primaryColor': '#252a34', 'edgeLabelBackground':'#ffffff', 'tertiaryColor': '#f5f5f5'}}}%%

graph TD
    %% --- STYLE DEFINITIONS ---
    classDef client fill:#ff6b6b,stroke:#333,stroke-width:2px,color:white;
    classDef gateway fill:#4ecdc4,stroke:#333,stroke-width:2px,color:white;
    classDef orchestrator fill:#45b7d1,stroke:#333,stroke-width:2px,color:white;
    classDef compute fill:#96ceb4,stroke:#333,stroke-width:2px,color:#333;
    classDef rag fill:#ffbe76,stroke:#333,stroke-width:2px,color:#333;
    classDef database fill:#2d3436,stroke:#333,stroke-width:2px,color:white,shape:cylinder;
    classDef external fill:#dfe6e9,stroke:#333,stroke-width:1px,color:#333,stroke-dasharray: 5 5;

    %% --- 1. CLIENT LAYER ---
    subgraph Clients ["ğŸ“¡ Client / Trigger Layer"]
        UI[ğŸ’» Web Dashboard]:::client
        API_C[ğŸ”Œ API Consumer]:::client
        Cron[â° Scheduled Cron]:::client
    end

    %% --- 2. GATEWAY LAYER ---
    subgraph Gateway ["ğŸ›¡ï¸ API Gateway & Load Balancer"]
        Nginx[NGINX / Kong Gateway]:::gateway
        Auth[ğŸ” Auth Service (JWT/OAuth)]:::gateway
    end

    UI --> Nginx
    API_C --> Nginx
    Cron --> Nginx
    Nginx -.->|Validate Token| Auth

    %% --- 3. ORCHESTRATION SERVICE (THE BRAIN) ---
    subgraph Orchestrator_Cluster ["ğŸ§  Core Orchestration Service (LangGraph)"]
        direction TB
        
        API_Orch[FastAPI Endpoint]:::orchestrator
        
        subgraph Graph_Logic ["State Machine (DAG)"]
            Planner[ğŸ“ Planner Node]:::orchestrator
            Router[ğŸ”€ Dispatcher/Router]:::orchestrator
            
            subgraph Consensus_Loop ["ğŸ”„ Consensus Sub-Architecture"]
                Critic[ğŸ§ Critic / Judge]:::orchestrator
                Verifier[âœ… Fact Checker]:::orchestrator
            end
            
            Writer[âœï¸ Report Generator]:::orchestrator
        end
        
        Checkpointer[ğŸ’¾ State Manager (Async)]:::orchestrator
    end

    Nginx ==>|/research/trigger| API_Orch
    API_Orch --> Planner
    Planner --> Router
    
    %% FEEDBACK LOOPS
    Critic --"Reject (Contradiction)"--> Router
    Verifier --"Failed Verification"--> Router
    Critic --"Approved"--> Writer

    %% --- 4. DOMAIN AGENT SERVICES ---
    subgraph Agents ["ğŸ•µï¸ Specialized Agent Services"]
        direction LR
        
        subgraph Fin_Agent ["Finance Agent"]
            Fin_Logic[market_analyst.py]:::compute
        end
        
        subgraph Legal_Agent ["Legal Agent"]
            Leg_Logic[legal_researcher.py]:::compute
        end
        
        subgraph Web_Agent ["Deep Web Agent"]
            Scraper_Logic[scrapper.py]:::compute
        end
    end

    Router == "gRPC/REST" ==> Fin_Agent
    Router == "gRPC/REST" ==> Legal_Agent
    Router == "gRPC/REST" ==> Web_Agent

    %% --- 5. TOOL SANDBOX (THE MUSCLE) ---
    subgraph Sandbox_Cluster ["ğŸ› ï¸ Tool Execution Engine (E2B / Docker)"]
        direction TB
        
        Code_Runner[ğŸ Python REPL (Isolated)]:::compute
        
        subgraph Data_Science_Stack ["libs"]
            Pandas[Pandas/Polars]:::compute
            Scikit[Scikit-Learn]:::compute
            Matplot[Plotly/Matplotlib]:::compute
        end
        
        DuckDB[(ğŸ¦† DuckDB - In-Memory OLAP)]:::database
    end

    Fin_Agent -.->|Exec Code| Code_Runner
    Web_Agent -.->|Exec Scraper| Code_Runner
    Code_Runner --> Pandas
    Pandas --> DuckDB

    %% --- 6. RAG & KNOWLEDGE LAYER ---
    subgraph RAG_System ["ğŸ“š Universal RAG Service"]
        direction TB
        
        Ingest[ğŸ“¥ Ingestion Pipeline]:::rag
        Retriever[ğŸ” Hybrid Search]:::rag
        Reranker[âš–ï¸ Cross-Encoder Rerank]:::rag
        
        subgraph Embed_Models ["Model Serving"]
            BiEnc[Bi-Encoder Model]:::rag
        end
    end

    Legal_Agent -.->|Query| Retriever
    Retriever --> BiEnc
    Retriever --> Reranker

    %% --- 7. PERSISTENCE LAYER ---
    subgraph Persistence ["ğŸ’¾ Data Persistence Layer"]
        Postgres[(ğŸ˜ PostgreSQL<br>Graph State & Users)]:::database
        VectorDB[(ğŸ’  Qdrant/Weaviate<br>Vector Store)]:::database
        Redis[(âš¡ Redis<br>Queue & Cache)]:::database
        S3[(ğŸ“¦ S3 / MinIO<br>Artifact Store)]:::database
    end

    Checkpointer --> Postgres
    RAG_System --> VectorDB
    API_Orch --> Redis
    Writer --> S3

    %% --- 8. EXTERNAL APIS ---
    subgraph External_World ["â˜ï¸ External World"]
        LLM_Prov[ğŸ¤– LLM Providers<br>(OpenAI/Gemini/Anthropic)]:::external
        Search_API[ğŸŒ Search APIs<br>(Tavily/Serp)]:::external
        Fin_API[ğŸ“ˆ Financial Data<br>(YFinance/OpenBB)]:::external
    end

    Planner -.->|Inference| LLM_Prov
    Fin_Agent -.-> Fin_API
    Web_Agent -.-> Search_API
    
```

### ğŸ” Architectural Explanation

This diagram is broken down into **Sub-Architectures** to show depth:

1.  **The Orchestration Cluster (The Brain):**
    *   Unlike simple scripts, this is a **State Machine**.
    *   **The Loop:** Notice the arrows from `Critic` back to `Router`. This represents the **Self-Correction** capability. If the data isn't good enough, the system loops back and tries again automatically.
    *   **Planner:** Breaks user input into atomic sub-tasks.

2.  **The Agent Layer (The Specialists):**
    *   These are decoupled Microservices. The `Finance Agent` is separate from the `Legal Agent`.
    *   This allows you to update the Financial logic without breaking the Legal logic.

3.  **The Tool Execution Engine (The Muscle):**
    *   This is the most "Advanced" part. It is an **Isolated Sandbox** (Docker/E2B).
    *   **DuckDB Integration:** Agents don't just "read" text. They dump raw CSV/JSON data into an in-memory DuckDB instance to run SQL queries and complex Pandas aggregations.

4.  **The RAG System (The Library):**
    *   Shows a full pipeline: `Ingest` -> `Hybrid Search` -> `Bi-Encoder` -> `Reranker`.
    *   This ensures high precision (Context Filtering) before data ever hits the LLM.

5.  **Data Persistence:**
    *   **PostgreSQL:** Saves the *thinking process* (LangGraph Checkpoints). You can pause a research job and resume it 2 days later.
    *   **S3/MinIO:** Stores the heavy artifacts (PDFs, Generated HTML Reports, Charts).
    *   **Redis:** Handles the message queue for long-running jobs (to prevent HTTP timeouts).
  
---
## ğŸ›  Tech Stack

| Component | Technology | Reasoning |
| :--- | :--- | :--- |
| **Language** | Python 3.11+ | Native support for AI & Data Science libraries. |
| **API Framework** | FastAPI | High-performance, async support, auto-OpenAPI generation. |
| **Orchestration** | LangGraph | Supports cyclic graphs and fine-grained state control. |
| **LLM Interface** | LiteLLM | Unified interface for OpenAI, Anthropic, Gemini, & Local LLMs. |
| **Vector DB** | Qdrant / Weaviate | High-speed semantic search. |
| **Analytical DB** | DuckDB | In-process SQL OLAP database for handling agent-generated datasets. |
| **Search/Scraping** | Tavily / Firecrawl | LLM-optimized web data extraction. |
| **State DB** | PostgreSQL | Persistence for long-running graph threads. |
| **Containerization** | Docker Compose | Microservices orchestration. |

---

## ğŸš€ Setup & Installation

### Prerequisites
*   Docker & Docker Compose
*   Python 3.11+
*   PostgreSQL (optional for local dev, required for prod)

### 1. Clone & Environment
```bash
git clone https://github.com/your-username/repo-name.git
cd repo-name
cp .env.example .env
```

### 2. Configuration (`.env`)
Fill in the required API keys. The system supports multi-provider routing.
```ini
# LLM Providers
OPENAI_API_KEY=sk-...
GEMINI_API_KEY=...
ANTHROPIC_API_KEY=...

# Search & Tools
TAVILY_API_KEY=tvly-...
FIRECRAWL_API_KEY=fc-...

# Database
POSTGRES_URI=postgresql://user:pass@localhost:5432/agent_db
QDRANT_URL=http://localhost:6333
```

### 3. Run Microservices (Docker)
```bash
docker-compose up --build -d
```
This spins up:
*   `orchestrator-service` (Port 8000)
*   `rag-service` (Port 8001)
*   `tool-sandbox` (Port 8002)
*   `db-postgres` (Port 5432)
*   `db-qdrant` (Port 6333)

---

## ğŸ”Œ API Usage

The system exposes a RESTful API via FastAPI.

### Trigger Deep Research
**Endpoint:** `POST /api/v1/research/trigger`

```json
{
  "query": "Identify top 10 Indonesian mining companies with high export volume.",
  "domain": "finance",
  "depth": "deep",
  "config": {
    "max_concurrent_agents": 3,
    "require_quantitative_analysis": true,
    "output_format": "html"
  }
}
```

### Check Status (Long Polling)
**Endpoint:** `GET /api/v1/research/status/{thread_id}`

```json
{
  "thread_id": "550e8400-e29b...",
  "status": "processing",
  "current_step": "financial_analysis_agent",
  "completed_steps": ["planner", "screener", "data_collection"],
  "artifacts": {
    "candidates_csv": "s3://bucket/data/candidates.csv"
  }
}
```

---

## ğŸ“‚ Project Structure

```text
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ orchestrator/       # Main LangGraph Logic
â”‚   â”‚   â”œâ”€â”€ agents/         # Planner, Critic, Writer definitions
â”‚   â”‚   â”œâ”€â”€ graph.py        # Node & Edge definitions
â”‚   â”‚   â””â”€â”€ main.py         # FastAPI entry point
â”‚   â”œâ”€â”€ rag_service/        # Embedding & Retrieval Logic
â”‚   â”‚   â””â”€â”€ ingestion.py    # PDF/Text ingestion pipelines
â”‚   â””â”€â”€ tool_runner/        # Python REPL & Sandbox
â”‚       â””â”€â”€ tools.py        # Pandas/Scikit scripts
â”œâ”€â”€ shared/                 # Shared Pydantic models & Utils
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ README.md
```

## ğŸ—º Roadmap

*   [x] Core Microservices Architecture
*   [x] LangGraph Implementation (Cyclic)
*   [x] DuckDB Integration for Agent Analytics
*   [ ] **Model Context Protocol (MCP)** Implementation for IDE integration.
*   [ ] **Multimodal Agents:** Adding Whisper (Audio) and Vision processing nodes.
*   [ ] **Human-in-the-Loop:** UI for pausing execution and manual approval of "Consensus" steps.

## ğŸ¤ Contribution

1.  Fork the repository.
2.  Create a feature branch (`git checkout -b feature/amazing-feature`).
3.  Commit your changes (`git commit -m 'Add some amazing feature'`).
4.  Push to the branch (`git push origin feature/amazing-feature`).
5.  Open a Pull Request.

## ğŸ“„ License

Distributed under the MIT License. See `LICENSE` for more information.
